{
  "hash": "7f28b3015616ab35e1f4665d1e416a76",
  "result": {
    "markdown": "---\ntitle: \"Missing covariate imputation\"\nexecute: \n  freeze: true\nknitr:\n  opts_chunk: \n    message: false\n---\n\n\n\n\nIn this example, we use the `nhanes2` data set from the `mice` R-package to illustrate how to do missing covariate imputation in INLA by using a measurement error model.\nAs noted in the paper, the `nhanes2` data set is really small, it only has 25 observations and 9 of them are missing, so this is not really a good application of this. However, we chose to use this as it is a data set that is commonly used in other missing data applications in INLA, and so we reasoned that using the same data set would make it easier to compare the implementations.\n\n## Loading packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mice)       # Just used for the nhanes2 data set\nlibrary(INLA)       # INLA modelling\nlibrary(dplyr)      # Data wrangling of the results\nlibrary(gt)         # Tables\nlibrary(tidyverse)  # Data wrangling and plotting\nlibrary(showtext)   # Font\nlibrary(colorspace) # Color adjustments\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninla.setOption(num.threads = \"1:1\")\n```\n:::\n\n\n## Loading and preparing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using the nhanes data set found in mice:\ndata(nhanes2)\n\nnhanes2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     age  bmi  hyp chl\n1  20-39   NA <NA>  NA\n2  40-59 22.7   no 187\n3  20-39   NA   no 187\n4  60-99   NA <NA>  NA\n5  20-39 20.4   no 113\n6  60-99   NA <NA> 184\n7  20-39 22.5   no 118\n8  20-39 30.1   no 187\n9  40-59 22.0   no 238\n10 40-59   NA <NA>  NA\n11 20-39   NA <NA>  NA\n12 40-59   NA <NA>  NA\n13 60-99 21.7   no 206\n14 40-59 28.7  yes 204\n15 20-39 29.6   no  NA\n16 20-39   NA <NA>  NA\n17 60-99 27.2  yes 284\n18 40-59 26.3  yes 199\n19 20-39 35.3   no 218\n20 60-99 25.5  yes  NA\n21 20-39   NA <NA>  NA\n22 20-39 33.2   no 229\n23 20-39 27.5   no 131\n24 60-99 24.9   no  NA\n25 40-59 27.4   no 186\n```\n:::\n\n```{.r .cell-code}\nn <- nrow(nhanes2)\n\n# Manually dummy-code age:\nage2 <- ifelse(nhanes2$age == \"40-59\", 1, 0)\nage3 <- ifelse(nhanes2$age == \"60-99\", 1, 0)\n\n# Center the response and continuous covariates\nchl <- scale(nhanes2$chl, scale = FALSE)[,1]\nbmi <- scale(nhanes2$bmi, scale = FALSE)[,1]\n```\n:::\n\n## Aim\nWe want to fit the model\n\n$$\nchl \\sim \\beta_0 + \\beta_{age2} age_2 + \\beta_{age3} age_3 + \\beta_{bmi} bmi + \\varepsilon,\n$$\nbut there is missingness in bmi, so we will consider two different imputation models for this.\n\n\n\n\n\n\n## Simple imputation model\nWe first fit a model that is identical to the one in Gómez-Rubio and Rue (2018).\n\n### Specifying priors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Priors for model of interest coefficients\nprior.beta = c(0, 0.001) # Gaussian, c(mean, precision)\n\n# Priors for exposure model coefficient\n#prior.alpha <- c(26.56, 1/71.07) # Gaussian, c(mean, precision)\n\n# Priors for y, measurement error\nprior.prec.y <- c(1, 0.00005) # Gamma\nprior.prec.u_c <- c(0.5, 0.5) # Gamma\n#prior.prec.x <- c(2.5-1,(2.5)*4.2^2) # Gamma\n\n# Initial values\nprec.y <- 1\nprec.u_c <- 1\n#prec.x <- 1/71.07\nprec.x <- 1/71.07\n```\n:::\n\n\n\n### Setting up the matrices for the joint model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nY <- matrix(NA, 3*n, 3)\n\nY[1:n, 1] <- chl             # Regression model of interest response\nY[n+(1:n), 2] <- bmi         # Error model response\nY[2*n+(1:n), 3] <- rep(0, n) # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, n), rep(NA, n))\nbeta.bmi <- c(1:n, rep(NA, n), rep(NA, n))\nbeta.age2 <- c(age2, rep(NA, n), rep(NA, n))\nbeta.age3 <- c(age3, rep(NA, n), rep(NA, n))\n\nid.x <- c(rep(NA, n), 1:n, 1:n) \nweight.x <- c(rep(1, n), rep(1, n), rep(-1, n))\n\noffset.imp <- c(rep(NA, n), rep(NA, n), rep(26.56, n))\n\ndd <- data.frame(Y = Y, \n                 beta.0 = beta.0,\n                 beta.bmi = beta.bmi,\n                 beta.age2 = beta.age2,\n                 beta.age3 = beta.age3,\n                 id.x = id.x,\n                 weight.x = weight.x,\n                 offset.imp = offset.imp)\n```\n:::\n\n\n### INLA formula\n\n::: {.cell}\n\n```{.r .cell-code}\nformula = Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + \n  f(beta.bmi, copy=\"id.x\", \n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  f(id.x, weight.x, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed=TRUE)))\n```\n:::\n\n\n### Scaling of ME precision\n\nSince we are not assuming any measurement error here, we need to \"turn off\" the error model by scaling the error precision to be very large (it makes no difference if we scale the precision only for the observed values or for the observed and missing values).\n\n::: {.cell}\n\n```{.r .cell-code}\nScale <- c(rep(1, n), rep(10^12, n), rep(1, n))\n```\n:::\n\n\n### Fitting the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_missing1 <- inla(formula, data = dd, scale = Scale, offset = log(dat$pop),\n                     family = c(\"gaussian\", \"gaussian\", \"gaussian\"),\n                     control.family = list(\n                       list(hyper = list(prec = list(initial = log(prec.y), \n                                                     param = prior.prec.y, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.u_c), \n                                                     param = prior.prec.u_c, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.x),\n                                                     fixed = TRUE)))\n                     ),\n                     control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2])),\n                     verbose=F)\nmodel_missing1$summary.fixed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               mean       sd 0.025quant  0.5quant 0.975quant mode          kld\nbeta.0    -17.60626 10.93451 -37.971728 -18.03594   5.183261   NA 9.910360e-08\nbeta.age2  29.24290 16.09734  -4.203562  29.84339  59.318094   NA 9.648499e-08\nbeta.age3  51.16447 20.73070   7.996870  52.09611  89.369885   NA 1.611619e-07\n```\n:::\n\n```{.r .cell-code}\nmodel_missing1$summary.hyperpar\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                  mean           sd\nPrecision for the Gaussian observations    0.001036804 0.0004234011\nPrecision for the Gaussian observations[2] 0.916159737 0.5484311863\nBeta for beta.bmi                          5.035216083 0.4842624861\n                                             0.025quant     0.5quant\nPrecision for the Gaussian observations    0.0003789667 0.0009755623\nPrecision for the Gaussian observations[2] 0.2023001516 0.8039241305\nBeta for beta.bmi                          4.1750752965 5.0067526677\n                                            0.975quant mode\nPrecision for the Gaussian observations    0.002025766   NA\nPrecision for the Gaussian observations[2] 2.276555004   NA\nBeta for beta.bmi                          6.082937710   NA\n```\n:::\n:::\n\n\n\n## Full imputation model\nThis model includes age as a covariate in the imputation model.\n\n### Specifying priors\n\nFor the intercepts and slopes of the model of interest and imputation model we set very wide priors centered at zero. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Priors for model of interest coefficients\nprior.beta = c(0, 1e-6) # Gaussian, c(mean, precision)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1e-6) # Gaussian, c(mean, precision)\n```\n:::\n\n\nFor the precision of $y$ and $x$ we set more informative priors. The precisions are given gamma priors, and in INLA this is parameterized by the shape and rate parameters. Let's first look at the precision for $y$. \n\nWe base our priors for $x$ and $y$  around the values that we want as the modes of the distributions. For $y$, we look at the regression `chl~bmi+age2+age3`. The standard error is estimated to be $29.1$. We decide we want $1/29.1^2$ to be the mode of our prior. Since the gamma distribution with shape $\\alpha$ and rate $\\beta$ has mode $\\frac{\\alpha-1}{\\beta}$, we can choose $\\alpha = s+1$ and $\\beta = s\\cdot29.1^2$ in order to get a distribution with mode equal to $1/29.1^2$. Then we need to choose $s$ to decide the spread, the variance of the inverse gamma distribution will decrease as $s$ increases. For $x$ we similarly construct the prior to have its mode at $4.1$.\n\nAn alternative approach could be to construct an upper limit for the variance by choosing that to be the variance of the covariate itself, as well as some lower limit, and then select the inverses of these limits to be the 2.7% and 97.5% quantiles in the gamma prior. in our case, the variance of `chl` is $2044$, so we would choose $1/2044$ to be the lower limit for $\\tau_y$. For the upper limit, we decide on roughly a 10th of that variation, so the upper limit is $1/204.4$. By specifying these points as the 2.7% and 97.5% quantiles, respectively, we can achieve the parameters of a gamma distribution with these quantiles through numerical optimization. We get the distribution $\\tau_y \\sim G(3.4, 1588)$. Similarly, for $x$ (`bmi`), we find that the sample variance of `bmi` is $17.8$, and so we could set the lower limit of $\\tau_x$ to $1/17.8$. Again, by choosing roughly a 10th of that variation we get a upper limit for the precision at $1/1.78$, giving the gamma distribution $\\tau_x \\sim G(3.4, 13.9)$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Priors for y, measurement error and true x-value precision\n# Start by getting a reasonable prior guess for the standard error of the regression and exp. models\nsummary(lm(chl~bmi+age2+age3))$sigma\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 29.10126\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(bmi~age2+age3))$sigma\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.160342\n```\n:::\n\n```{.r .cell-code}\n# Use those values to create reasonable priors:\ns <- 0.5\nprior.prec.y <- c(s+1, s*29.1^2) # Gamma\nprior.prec.x <- c(s+1, s*4.1^2) # Gamma\n\n# We can visualize these priors:\ncurve(dgamma(x, s+1, s*29.1^2), 0, 0.02) \nabline(v=1/(29.1^2))\n```\n\n::: {.cell-output-display}\n![](missing_covariate_imputation_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncurve(dgamma(x, s+1, s*4.1^2), 0, 1)\nabline(v=1/(4.2^2))\n```\n\n::: {.cell-output-display}\n![](missing_covariate_imputation_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Initial values\nprec.y <- 1/29.1^2\nprec.u_c <- 1\nprec.x <- 1/4.2^2\n```\n:::\n\n\n### Setting up the matrices for the joint model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nY <- matrix(NA, 3*n, 3)\n\n\nY[1:n, 1] <- chl             # Regression model of interest response\nY[n+(1:n), 2] <- bmi         # Error model response\nY[2*n+(1:n), 3] <- rep(0, n) # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, n), rep(NA, n))\nbeta.bmi <- c(1:n, rep(NA, n), rep(NA, n))\nbeta.age2 <- c(age2, rep(NA, n), rep(NA, n))\nbeta.age3 <- c(age3, rep(NA, n), rep(NA, n))\n\nid.x <- c(rep(NA, n), 1:n, 1:n) \nweight.x <- c(rep(1, n), rep(1, n), rep(-1, n))\n\nalpha.0 <- c(rep(NA, n), rep(NA, n), rep(1, n))\nalpha.age2 <- c(rep(NA, n), rep(NA, n), age2)\nalpha.age3 <- c(rep(NA, n), rep(NA, n), age3)\n\ndd <- data.frame(Y = Y, \n                 beta.0 = beta.0,\n                 beta.bmi = beta.bmi,\n                 beta.age2 = beta.age2,\n                 beta.age3 = beta.age3,\n                 id.x = id.x,\n                 weight.x = weight.x,\n                 alpha.0 = alpha.0,\n                 alpha.age2 = alpha.age2,\n                 alpha.age3 = alpha.age3)\n```\n:::\n\n\n### INLA formula\n\n::: {.cell}\n\n```{.r .cell-code}\nformula = Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + \n  f(beta.bmi, copy=\"id.x\", \n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  f(id.x, weight.x, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  alpha.0 + alpha.age2 + alpha.age3\n```\n:::\n\n\n### Scaling of ME precision\n\nSince we are (again) not assuming any measurement error here, we need to \"turn off\" the error model by scaling the error precision to be very large (it makes no difference if we scale the precision only for the observed values or for the observed and missing values).\n\n::: {.cell}\n\n```{.r .cell-code}\nScale <- c(rep(1, n), rep(10^12, n), rep(1, n))\n```\n:::\n\n\n### Fitting the model\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_missing2 <- inla(formula, data = dd, scale = Scale,\n                     family = c(\"gaussian\", \"gaussian\", \"gaussian\"),\n                     control.family = list(\n                       list(hyper = list(prec = list(initial = log(prec.y), \n                                                     param = prior.prec.y, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.u_c),\n                                                     fixed = TRUE))),\n                       list(hyper = list(prec = list(initial = log(prec.x), \n                                                     param = prior.prec.x, \n                                                     fixed = FALSE)))\n                     ),\n                     control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],  \n                                   alpha.0 = prior.alpha[1], \n                                   alpha.age2 = prior.alpha[1],\n                                   alpha.age3 = prior.alpha[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   alpha.0 = prior.alpha[2], \n                                   alpha.age2 = prior.alpha[2],\n                                   alpha.age3 = prior.alpha[2])),\n                     verbose=F)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save results:\nsaveRDS(model_missing2, file = \"results/model_missing2.rds\")\n```\n:::\n\n\n## Fitting a complete case model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Where is bmi missing? \nmissing_bmi <- is.na(bmi)\n\ndd_naive <- data.frame(Y = chl, \n                       beta.0 = rep(1, length(bmi)),\n                       beta.bmi = bmi, \n                       beta.age2 = age2, \n                       beta.age3 = age3)[!missing_bmi, ]\n\n\n# Formula\nformula <- Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + beta.bmi\n\n# Fit model\nmodel_naive <- inla(formula,\n              data = dd_naive,\n              family = c(\"gaussian\"),\n              control.family = list(\n                list(hyper = list(prec = list(initial = prec.y, \n                                              param = prior.prec.y, \n                                              fixed = FALSE)))),\n              control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],\n                                   beta.bmi = prior.beta[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   beta.bmi = prior.beta[2]))\n)\n```\n:::\n\n\n\n\n## Results\n\nThe posterior means and standard deviations are presented in the table below. Note that the data set is quite small (25 observations where 9 are missing), and so the differing result should not be interpreted too seriously.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div id=\"niwvxbffxs\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#niwvxbffxs .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#niwvxbffxs .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#niwvxbffxs .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#niwvxbffxs .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#niwvxbffxs .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#niwvxbffxs .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#niwvxbffxs .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#niwvxbffxs .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#niwvxbffxs .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#niwvxbffxs .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#niwvxbffxs .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#niwvxbffxs .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#niwvxbffxs .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#niwvxbffxs .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#niwvxbffxs .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#niwvxbffxs .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#niwvxbffxs .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#niwvxbffxs .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#niwvxbffxs .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#niwvxbffxs .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#niwvxbffxs .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#niwvxbffxs .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#niwvxbffxs .gt_left {\n  text-align: left;\n}\n\n#niwvxbffxs .gt_center {\n  text-align: center;\n}\n\n#niwvxbffxs .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#niwvxbffxs .gt_font_normal {\n  font-weight: normal;\n}\n\n#niwvxbffxs .gt_font_bold {\n  font-weight: bold;\n}\n\n#niwvxbffxs .gt_font_italic {\n  font-style: italic;\n}\n\n#niwvxbffxs .gt_super {\n  font-size: 65%;\n}\n\n#niwvxbffxs .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#niwvxbffxs .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#niwvxbffxs .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#niwvxbffxs .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#niwvxbffxs .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#niwvxbffxs .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#niwvxbffxs .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\"></th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\">\n        <span class=\"gt_column_spanner\">me_adjusted</span>\n      </th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\">\n        <span class=\"gt_column_spanner\">naive</span>\n      </th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\">\n        <span class=\"gt_column_spanner\">inla_mcmc</span>\n      </th>\n    </tr>\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">lower</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">upper</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">lower</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">upper</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">lower</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">upper</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <td colspan=\"10\" class=\"gt_group_heading\">Model of interest</td>\n    </tr>\n    <tr class=\"gt_row_group_first\"><th scope=\"row\" class=\"gt_row gt_left gt_stub\">beta.0</th>\n<td class=\"gt_row gt_right\">-32.246</td>\n<td class=\"gt_row gt_right\">-53.825</td>\n<td class=\"gt_row gt_right\">-10.209</td>\n<td class=\"gt_row gt_right\">-36.471</td>\n<td class=\"gt_row gt_right\">-60.971</td>\n<td class=\"gt_row gt_right\">-11.955</td>\n<td class=\"gt_row gt_right\">43.469</td>\n<td class=\"gt_row gt_right\">-79.233</td>\n<td class=\"gt_row gt_right\">166.171</td></tr>\n    <tr><th scope=\"row\" class=\"gt_row gt_left gt_stub\">beta.age2</th>\n<td class=\"gt_row gt_right\">49.780</td>\n<td class=\"gt_row gt_right\">16.172</td>\n<td class=\"gt_row gt_right\">82.716</td>\n<td class=\"gt_row gt_right\">55.767</td>\n<td class=\"gt_row gt_right\">19.014</td>\n<td class=\"gt_row gt_right\">92.496</td>\n<td class=\"gt_row gt_right\">29.501</td>\n<td class=\"gt_row gt_right\">-5.526</td>\n<td class=\"gt_row gt_right\">64.528</td></tr>\n    <tr><th scope=\"row\" class=\"gt_row gt_left gt_stub\">beta.age3</th>\n<td class=\"gt_row gt_right\">83.479</td>\n<td class=\"gt_row gt_right\">40.509</td>\n<td class=\"gt_row gt_right\">124.367</td>\n<td class=\"gt_row gt_right\">104.643</td>\n<td class=\"gt_row gt_right\">55.072</td>\n<td class=\"gt_row gt_right\">154.173</td>\n<td class=\"gt_row gt_right\">49.449</td>\n<td class=\"gt_row gt_right\">3.963</td>\n<td class=\"gt_row gt_right\">94.935</td></tr>\n    <tr><th scope=\"row\" class=\"gt_row gt_left gt_stub\">Beta for beta.bmi</th>\n<td class=\"gt_row gt_right\">4.935</td>\n<td class=\"gt_row gt_right\">3.541</td>\n<td class=\"gt_row gt_right\">6.181</td>\n<td class=\"gt_row gt_right\">6.919</td>\n<td class=\"gt_row gt_right\">3.026</td>\n<td class=\"gt_row gt_right\">10.811</td>\n<td class=\"gt_row gt_right\">4.864</td>\n<td class=\"gt_row gt_right\">0.540</td>\n<td class=\"gt_row gt_right\">9.188</td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <td colspan=\"10\" class=\"gt_group_heading\">Imputation model</td>\n    </tr>\n    <tr class=\"gt_row_group_first\"><th scope=\"row\" class=\"gt_row gt_left gt_stub\">alpha.0</th>\n<td class=\"gt_row gt_right\">1.983</td>\n<td class=\"gt_row gt_right\">-0.979</td>\n<td class=\"gt_row gt_right\">4.978</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td></tr>\n    <tr><th scope=\"row\" class=\"gt_row gt_left gt_stub\">alpha.age2</th>\n<td class=\"gt_row gt_right\">-3.126</td>\n<td class=\"gt_row gt_right\">-7.829</td>\n<td class=\"gt_row gt_right\">1.544</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td></tr>\n    <tr><th scope=\"row\" class=\"gt_row gt_left gt_stub\">alpha.age3</th>\n<td class=\"gt_row gt_right\">-4.525</td>\n<td class=\"gt_row gt_right\">-9.547</td>\n<td class=\"gt_row gt_right\">0.320</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td>\n<td class=\"gt_row gt_right\">NA</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.showtext='true'}\n::: {.cell-output-display}\n![](missing_covariate_imputation_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\nWe can also look at the imputed values themselves, they can be found in `marginals.random$id.x` inside the model object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbmi_imputed <- model_missing2$marginals.random$id.x[missing_bmi]\nbmi_imp_df <- data.table::rbindlist(lapply(bmi_imputed, as.data.frame), idcol = TRUE)\n\nggplot(bmi_imp_df, aes(x = x, y = y)) +\n  geom_line() +\n  facet_wrap(~ .id, ncol = 3) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](missing_covariate_imputation_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\nA summary can also be seen from `summary.random$id.x`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_missing2$summary.random$id.x[,1:6]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   ID       mean           sd  0.025quant   0.5quant 0.975quant\n1   1  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n2   2 -3.8624998 0.0009999933  -3.8644610 -3.8624998 -3.8605387\n3   3  3.2045709 3.3767919876  -3.4545358  3.2001626  9.8975173\n4   4 -2.5416313 4.5282288945 -11.6122240 -2.5139190  6.3676961\n5   5 -6.1624995 0.0009999933  -6.1644607 -6.1624995 -6.1605384\n6   6 -5.7573424 3.8336379811 -13.3935391 -5.7357398  1.7336245\n7   7 -4.0624997 0.0009999933  -4.0644609 -4.0624997 -4.0605386\n8   8  3.5375000 0.0009999933   3.5355388  3.5375000  3.5394611\n9   9 -4.5624993 0.0009999933  -4.5644605 -4.5624993 -4.5605382\n10 10 -1.1424814 4.4628547510 -10.0052047 -1.1424825  7.7202482\n11 11  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n12 12 -1.1424814 4.4628547510 -10.0052047 -1.1424825  7.7202482\n13 13 -4.8624999 0.0009999933  -4.8644611 -4.8624999 -4.8605388\n14 14  2.1374996 0.0009999933   2.1355385  2.1374996  2.1394608\n15 15  3.0374999 0.0009999933   3.0355388  3.0374999  3.0394611\n16 16  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n17 17  0.6375001 0.0009999933   0.6355389  0.6375001  0.6394612\n18 18 -0.2625001 0.0009999933  -0.2644613 -0.2625001 -0.2605390\n19 19  8.7374996 0.0009999933   8.7355385  8.7374996  8.7394608\n20 20 -1.0625001 0.0009999933  -1.0644612 -1.0625001 -1.0605390\n21 21  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n22 22  6.6374999 0.0009999933   6.6355388  6.6374999  6.6394611\n23 23  0.9374998 0.0009999933   0.9355387  0.9374998  0.9394610\n24 24 -1.6625001 0.0009999933  -1.6644612 -1.6625001 -1.6605389\n25 25  0.8374996 0.0009999933   0.8355385  0.8374996  0.8394608\n```\n:::\n:::\n\n\n\n\n### Model summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_missing2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\n   c(\"inla.core(formula = formula, family = family, contrasts = contrasts, \n   \", \" data = data, quantiles = quantiles, E = E, offset = offset, \", \" \n   scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, \n   \", \" lp.scale = lp.scale, link.covariates = link.covariates, verbose = \n   verbose, \", \" lincomb = lincomb, selection = selection, control.compute \n   = control.compute, \", \" control.predictor = control.predictor, \n   control.family = control.family, \", \" control.inla = control.inla, \n   control.fixed = control.fixed, \", \" control.mode = control.mode, \n   control.expert = control.expert, \", \" control.hazard = control.hazard, \n   control.lincomb = control.lincomb, \", \" control.update = \n   control.update, control.lp.scale = control.lp.scale, \", \" \n   control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, \n   \", \" inla.call = inla.call, inla.arg = inla.arg, num.threads = \n   num.threads, \", \" blas.num.threads = blas.num.threads, keep = keep, \n   working.directory = working.directory, \", \" silent = silent, inla.mode \n   = inla.mode, safe = FALSE, debug = debug, \", \" .parent.frame = \n   .parent.frame)\") \nTime used:\n    Pre = 2.94, Running = 0.278, Post = 0.0209, Total = 3.24 \nFixed effects:\n              mean     sd 0.025quant 0.5quant 0.975quant mode kld\nbeta.0     -32.246 10.999    -53.825  -32.333    -10.209   NA   0\nbeta.age2   49.780 16.772     16.172   49.906     82.716   NA   0\nbeta.age3   83.479 21.180     40.509   83.873    124.367   NA   0\nalpha.0      1.983  1.501     -0.979    1.978      4.978   NA   0\nalpha.age2  -3.126  2.361     -7.829   -3.120      1.544   NA   0\nalpha.age3  -4.525  2.487     -9.547   -4.494      0.320   NA   0\n\nRandom effects:\n  Name\t  Model\n    id.x IID model\n   beta.bmi Copy\n\nModel hyperparameters:\n                                            mean    sd 0.025quant 0.5quant\nPrecision for the Gaussian observations    0.001 0.001      0.001    0.001\nPrecision for the Gaussian observations[3] 0.063 0.016      0.036    0.062\nBeta for beta.bmi                          4.935 0.657      3.541    4.953\n                                           0.975quant mode\nPrecision for the Gaussian observations         0.003   NA\nPrecision for the Gaussian observations[3]      0.098   NA\nBeta for beta.bmi                               6.181   NA\n\nMarginal log-Likelihood:  -366.84 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n```\n:::\n:::\n\n\n\n\n\n\n### References\n\nGómez-Rubio, V., & Rue, H. (2018). Markov chain Monte Carlo with the integrated nested Laplace approximation. *Statistics and Computing*, 28, 1033–1051. doi: 10.1007/s11222-017-9778-y\n\n",
    "supporting": [
      "missing_covariate_imputation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}