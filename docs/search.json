[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplementary material and reproducible research files for article “A Joint Bayesian Framework for Measurement Error and Missing Data using Integrated Nested Laplace Approximations”",
    "section": "",
    "text": "Authors: Skarstein, E., Martino, S., Muff, S.\nThis supplementary material was written by Skarstein, E., but code for analysis was developed jointly between authors.\nIn case of any questions or comments, please do not hesitate to contact emma.s.skarstein@ntnu.no!\nThis website contains scripts, tutorials and data to reproduce all analysis and figures from the manuscript."
  },
  {
    "objectID": "index.html#examples",
    "href": "index.html#examples",
    "title": "Supplementary material and reproducible research files for article “A Joint Bayesian Framework for Measurement Error and Missing Data using Integrated Nested Laplace Approximations”",
    "section": "Examples",
    "text": "Examples\nThese include scripts to run the code for analysis, including comments and explanations.\nFor a step-by-step introduction with detailed explanations, see Simulation example. This is a single sun of the simulation study shown in the paper, and the full code for the study can be found in Simulation study. The data and model used in these examples reflect the most general case where we have a covariate with classical and Berkson measurement error, as well as missing data. For many users inlabru might be more intuitive than plain INLA, and so we have also included the same model implemented in inlabru in Example in inlabru.\nThe remaining examples are variations on the above model using different data sets, see the table below for an overview of the different types of ME in the different examples.\n\n\n\nExample\nClassical ME\nBerkson ME\nMissing data\n\n\n\n\nMissing covariate imputation\n\n\nx\n\n\nMissing and mismeasured covariate\nx\n\nx\n\n\nSimulation study\nx\nx\nx\n\n\nSimulation example\nx\nx\nx\n\n\nExample in inlabru\nx\nx\nx"
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "Supplementary material and reproducible research files for article “A Joint Bayesian Framework for Measurement Error and Missing Data using Integrated Nested Laplace Approximations”",
    "section": "Datasets",
    "text": "Datasets\nAll the data sets that are used in the paper can be downloaded manually from [link to github repo], or like this:\n\n# Code to download data"
  },
  {
    "objectID": "index.html#session-info",
    "href": "index.html#session-info",
    "title": "Supplementary material and reproducible research files for article “A Joint Bayesian Framework for Measurement Error and Missing Data using Integrated Nested Laplace Approximations”",
    "section": "Session info",
    "text": "Session info\nThe code was written and run in R with the following software versions:\n\n\n\ninla.version()\nR-INLA version ..........: 22.05.07\nDate ....................: Sat May 7 12:43:31 PM +03 2022 (Version_22.05.07)\nMaintainers .............: Havard Rue <hrue@r-inla.org>\n                         : Finn Lindgren <finn.lindgren@gmail.com>\n                         : Elias Teixeira Krainski <elias@r-inla.org>\nMain web-page ...........: www.r-inla.org\nDownload-page ...........: inla.r-inla-download.org\nRepository ..............: github.com/hrue/r-inla\nEmail support ...........: help@r-inla.org\n                         : r-inla-discussion-group@googlegroups.com\n\n\n\n Current session info \n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Oslo\n date     2022-12-13\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version  date (UTC) lib source\n class          7.3-20   2022-01-16 [1] CRAN (R 4.2.1)\n classInt       0.4-8    2022-09-29 [1] CRAN (R 4.2.0)\n cli            3.4.1    2022-09-23 [1] CRAN (R 4.2.0)\n codetools      0.2-18   2020-11-04 [1] CRAN (R 4.2.1)\n colorspace     2.0-3    2022-02-21 [1] CRAN (R 4.2.0)\n DBI            1.1.3    2022-06-18 [1] CRAN (R 4.2.0)\n digest         0.6.30   2022-10-18 [1] CRAN (R 4.2.0)\n e1071          1.7-12   2022-10-24 [1] CRAN (R 4.2.0)\n fansi          1.0.3    2022-03-24 [1] CRAN (R 4.2.0)\n farver         2.1.1    2022-07-06 [1] CRAN (R 4.2.0)\n foreach      * 1.5.2    2022-02-02 [1] CRAN (R 4.2.0)\n ggplot2        3.3.6    2022-05-03 [1] CRAN (R 4.2.0)\n glue           1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n gtable         0.3.1    2022-09-01 [1] CRAN (R 4.2.0)\n INLA         * 22.05.07 2022-05-07 [1] local\n inlabru        2.6.0    2022-10-24 [1] CRAN (R 4.2.0)\n isoband        0.2.6    2022-10-06 [1] CRAN (R 4.2.0)\n iterators      1.0.14   2022-02-05 [1] CRAN (R 4.2.0)\n KernSmooth     2.23-20  2021-05-03 [1] CRAN (R 4.2.1)\n labeling       0.4.2    2020-10-20 [1] CRAN (R 4.2.0)\n lattice        0.20-45  2021-09-22 [1] CRAN (R 4.2.1)\n lifecycle      1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n magrittr       2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n MASS           7.3-57   2022-04-22 [1] CRAN (R 4.2.1)\n Matrix       * 1.5-1    2022-09-13 [1] CRAN (R 4.2.0)\n MatrixModels   0.5-1    2022-09-11 [1] CRAN (R 4.2.0)\n mgcv           1.8-40   2022-03-29 [1] CRAN (R 4.2.1)\n munsell        0.5.0    2018-06-12 [1] CRAN (R 4.2.0)\n nlme           3.1-157  2022-03-25 [1] CRAN (R 4.2.1)\n patchwork      1.1.2    2022-08-19 [1] CRAN (R 4.2.0)\n pillar         1.8.1    2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig      2.0.3    2019-09-22 [1] CRAN (R 4.2.0)\n plyr           1.8.7    2022-03-24 [1] CRAN (R 4.2.0)\n proxy          0.4-27   2022-06-09 [1] CRAN (R 4.2.0)\n R6             2.5.1    2021-08-19 [1] CRAN (R 4.2.0)\n RColorBrewer   1.1-3    2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp           1.0.9    2022-07-08 [1] CRAN (R 4.2.0)\n rgdal          1.5-32   2022-05-09 [1] CRAN (R 4.2.0)\n rgeos          0.5-9    2021-12-15 [1] CRAN (R 4.2.0)\n rlang          1.0.6    2022-09-24 [1] CRAN (R 4.2.0)\n s2             1.1.0    2022-07-18 [1] CRAN (R 4.2.0)\n scales         1.2.1    2022-08-20 [1] CRAN (R 4.2.0)\n sf             1.0-8    2022-07-14 [1] CRAN (R 4.2.0)\n sp           * 1.5-0    2022-06-05 [1] CRAN (R 4.2.0)\n tibble         3.1.8    2022-07-22 [1] CRAN (R 4.2.0)\n units          0.8-0    2022-02-05 [1] CRAN (R 4.2.0)\n utf8           1.2.2    2021-07-24 [1] CRAN (R 4.2.0)\n vctrs          0.5.0    2022-10-22 [1] CRAN (R 4.2.0)\n viridisLite    0.4.1    2022-08-22 [1] CRAN (R 4.2.0)\n withr          2.5.0    2022-03-03 [1] CRAN (R 4.2.0)\n wk             0.7.0    2022-10-13 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "missing_covariate_imputation.html",
    "href": "missing_covariate_imputation.html",
    "title": "Missing covariate imputation",
    "section": "",
    "text": "In this example, we use the nhanes2 data set from the mice R-package to illustrate how to do missing covariate imputation in INLA by using a measurement error model. As noted in the paper, the nhanes2 data set is really small, it only has 25 observations and 9 of them are missing, so this is not really a good application of this. However, we chose to use this as it is a data set that is commonly used in other missing data applications in INLA, and so we reasoned that using the same data set would make it easier to compare the implementations."
  },
  {
    "objectID": "missing_covariate_imputation.html#loading-packages",
    "href": "missing_covariate_imputation.html#loading-packages",
    "title": "Missing covariate imputation",
    "section": "Loading packages",
    "text": "Loading packages\n\nlibrary(mice)       # Just used for the nhanes2 data set\nlibrary(INLA)       # INLA modelling\nlibrary(dplyr)      # Data wrangling of the results\nlibrary(gt)         # Tables\nlibrary(tidyverse)  # Data wrangling and plotting\nlibrary(showtext)   # Font\nlibrary(colorspace) # Color adjustments\nlibrary(MCMCpack)   # dinvgamma()\n\n\ninla.setOption(num.threads = \"1:1\")"
  },
  {
    "objectID": "missing_covariate_imputation.html#loading-and-preparing-the-data",
    "href": "missing_covariate_imputation.html#loading-and-preparing-the-data",
    "title": "Missing covariate imputation",
    "section": "Loading and preparing the data",
    "text": "Loading and preparing the data\n\n# Using the nhanes data set found in mice so we can compare to mice:\ndata(nhanes2)\n\nhead(nhanes2)\n\n    age  bmi  hyp chl\n1 20-39   NA <NA>  NA\n2 40-59 22.7   no 187\n3 20-39   NA   no 187\n4 60-99   NA <NA>  NA\n5 20-39 20.4   no 113\n6 60-99   NA <NA> 184\n\nn <- nrow(nhanes2)\n\n# Manually dummy-code age:\nage2 <- ifelse(nhanes2$age == \"40-59\", 1, 0)\nage3 <- ifelse(nhanes2$age == \"60-99\", 1, 0)\n\n# Center the response and continuous covariates\nchl <- scale(nhanes2$chl, scale = FALSE)[,1]\nbmi <- scale(nhanes2$bmi, scale = FALSE)[,1]"
  },
  {
    "objectID": "missing_covariate_imputation.html#modelling",
    "href": "missing_covariate_imputation.html#modelling",
    "title": "Missing covariate imputation",
    "section": "Modelling",
    "text": "Modelling\nWe want to fit the model\n\\[\nchl \\sim \\beta_0 + \\beta_{age2} age_2 + \\beta_{age3} age_3 + \\beta_{bmi} bmi\n\\]\n\nSpecifying priors\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 1e-6) # Gaussian, c(mean, precision)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1e-6) # Gaussian, c(mean, precision)\n\n# Priors for y, measurement error and true x-value precision\n# Start by getting a reasonable prior guess for the standard error of the regression and exp. models\nsummary(lm(chl~bmi+age2+age3))$sigma\n\n[1] 29.10126\n\nsummary(lm(bmi~age2+age3))$sigma\n\n[1] 4.160342\n\n# Use those values to create reasonable priors:\nprior.prec.y <- c(2.5-1,(2.5)*29.1^2) # Gamma\nprior.prec.u_c <- c(0.5, 0.5) # Gamma\nprior.prec.x <- c(2.5-1,(2.5)*4.2^2) # Gamma\n\n# We can visualize these priors:\n#curve(dinvgamma(x, 2.5-1,(2.5)*29.1^2), 0, 2000)\n#abline(v=29.1^2)\n\n#curve(dinvgamma(x,2.5-1,(2.5)*4.1^2), 0, 50)\n#abline(v=4.2^2)\n\n# Initial values\nprec.y <- 1/29.1^2\nprec.u_c <- 1\nprec.x <- 1/4.2^2\n\n\n\nSetting up the matrices for the joint model\n\nY <- matrix(NA, 3*n, 3)\n\n\nY[1:n, 1] <- chl             # Regression model of interest response\nY[n+(1:n), 2] <- bmi         # Error model response\nY[2*n+(1:n), 3] <- rep(0, n) # Exposure model response\n\nbeta.0 <- c(rep(1, n), rep(NA, n), rep(NA, n))\nbeta.bmi <- c(1:n, rep(NA, n), rep(NA, n))\nbeta.age2 <- c(age2, rep(NA, n), rep(NA, n))\nbeta.age3 <- c(age3, rep(NA, n), rep(NA, n))\n\nid.x <- c(rep(NA, n), 1:n, 1:n) \nweight.x <- c(rep(1, n), rep(1, n), rep(-1, n))\n\nalpha.0 <- c(rep(NA, n), rep(NA, n), rep(1, n))\nalpha.age2 <- c(rep(NA, n), rep(NA, n), age2)\nalpha.age3 <- c(rep(NA, n), rep(NA, n), age3)\n\ndd <- data.frame(Y = Y, \n                 beta.0 = beta.0,\n                 beta.bmi = beta.bmi,\n                 beta.age2 = beta.age2,\n                 beta.age3 = beta.age3,\n                 id.x = id.x,\n                 weight.x = weight.x,\n                 alpha.0 = alpha.0,\n                 alpha.age2 = alpha.age2,\n                 alpha.age3 = alpha.age3)\n\n\n\nINLA formula\n\nformula = Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + \n  f(beta.bmi, copy=\"id.x\", \n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  f(id.x, weight.x, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  alpha.0 + alpha.age2 + alpha.age3\n\n\n\nScaling of ME precision\nSince we are not assuming any measurement error here, we need to “turn off” the error model by scaling the error precision to be very large (it makes no difference if we scale the precision only for the observed values or for the observed and missing values).\n\nScale <- c(rep(1, n), rep(10^12, n), rep(1, n))\n\n\n\nFitting the model\n\nmodel_missing <- inla(formula, data = dd, scale = Scale,\n                     family = c(\"gaussian\", \"gaussian\", \"gaussian\"),\n                     control.family = list(\n                       list(hyper = list(prec = list(initial = log(prec.y), \n                                                     param = prior.prec.y, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.u_c), \n                                                     param = prior.prec.u_c, \n                                                     fixed = TRUE))),\n                       list(hyper = list(prec = list(initial = log(prec.x), \n                                                     param = prior.prec.x, \n                                                     fixed = FALSE)))\n                     ),\n                     control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],  \n                                   alpha.0 = prior.alpha[1], \n                                   alpha.age2 = prior.alpha[1],\n                                   alpha.age3 = prior.alpha[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   alpha.0 = prior.alpha[2], \n                                   alpha.age2 = prior.alpha[2],\n                                   alpha.age3 = prior.alpha[2])),\n                     verbose=F)\n\n\n# Save results:\nsaveRDS(model_missing, file = \"results/model_missing.rds\")\n\n\n\nFitting a complete case model\n\n# Where is bmi missing? \nmissing_bmi <- is.na(bmi)\n\ndd_naive <- data.frame(Y = chl, \n                       beta.0 = rep(1, length(bmi)),\n                       beta.bmi = bmi, \n                       beta.age2 = age2, \n                       beta.age3 = age3)[!missing_bmi, ]\n\n\n# Formula\nformula <- Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + beta.bmi\n\n# Fit model\nmodel_naive <- inla(formula,\n              data = dd_naive,\n              family = c(\"gaussian\"),\n              control.family = list(\n                list(hyper = list(prec = list(initial = prec.y, \n                                              param = prior.prec.y, \n                                              fixed = FALSE)))),\n              control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],\n                                   beta.bmi = prior.beta[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   beta.bmi = prior.beta[2])),\n)"
  },
  {
    "objectID": "missing_covariate_imputation.html#results",
    "href": "missing_covariate_imputation.html#results",
    "title": "Missing covariate imputation",
    "section": "Results",
    "text": "Results\nThe posterior means and standard deviations are presented in the table below. Note that the data set is quite small (25 observations where 9 are missing), and so the differing result should not be interpreted too seriously.\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      \n      \n        me_adjusted\n      \n      \n        naive\n      \n      \n        inla_mcmc\n      \n    \n    \n      mean\n      sd\n      mean\n      sd\n      mean\n      sd\n    \n  \n  \n    \n      Model of interest\n    \n    beta.0\n-31.114\n12.721\n-36.459\n14.532\n43.469\n62.603\n    beta.age2\n47.983\n19.445\n55.749\n21.786\n29.501\n17.871\n    beta.age3\n79.842\n24.034\n104.611\n29.380\n49.449\n23.207\n    Beta for beta.bmi\n4.559\n0.373\n6.918\n2.308\n4.864\n2.206\n    \n      Imputation model\n    \n    alpha.0\n1.974\n1.700\nNA\nNA\nNA\nNA\n    alpha.age2\n-3.117\n2.666\nNA\nNA\nNA\nNA\n    alpha.age3\n-4.457\n2.816\nNA\nNA\nNA\nNA\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel summary\n\nsummary(model_missing)\n\n\nCall:\n   c(\"inla.core(formula = formula, family = family, contrasts = contrasts, \n   \", \" data = data, quantiles = quantiles, E = E, offset = offset, \", \" \n   scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, \n   \", \" lp.scale = lp.scale, link.covariates = link.covariates, verbose = \n   verbose, \", \" lincomb = lincomb, selection = selection, control.compute \n   = control.compute, \", \" control.predictor = control.predictor, \n   control.family = control.family, \", \" control.inla = control.inla, \n   control.fixed = control.fixed, \", \" control.mode = control.mode, \n   control.expert = control.expert, \", \" control.hazard = control.hazard, \n   control.lincomb = control.lincomb, \", \" control.update = \n   control.update, control.lp.scale = control.lp.scale, \", \" \n   control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, \n   \", \" inla.call = inla.call, inla.arg = inla.arg, num.threads = \n   num.threads, \", \" blas.num.threads = blas.num.threads, keep = keep, \n   working.directory = working.directory, \", \" silent = silent, inla.mode \n   = inla.mode, safe = FALSE, debug = debug, \", \" .parent.frame = \n   .parent.frame)\") \nTime used:\n    Pre = 3.34, Running = 0.352, Post = 0.0287, Total = 3.72 \nFixed effects:\n              mean     sd 0.025quant 0.5quant 0.975quant mode kld\nbeta.0     -31.114 12.721    -56.265  -31.140     -5.851   NA   0\nbeta.age2   47.983 19.445      9.395   48.007     86.493   NA   0\nbeta.age3   79.842 24.034     31.700   80.057    126.835   NA   0\nalpha.0      1.974  1.700     -1.376    1.969      5.352   NA   0\nalpha.age2  -3.117  2.666     -8.408   -3.112      2.146   NA   0\nalpha.age3  -4.457  2.816    -10.103   -4.430      1.037   NA   0\n\nRandom effects:\n  Name    Model\n    id.x IID model\n   beta.bmi Copy\n\nModel hyperparameters:\n                                            mean    sd 0.025quant 0.5quant\nPrecision for the Gaussian observations    0.001 0.000      0.001    0.001\nPrecision for the Gaussian observations[3] 0.052 0.016      0.025    0.050\nBeta for beta.bmi                          4.559 0.373      3.748    4.573\n                                           0.975quant mode\nPrecision for the Gaussian observations         0.002   NA\nPrecision for the Gaussian observations[3]      0.088   NA\nBeta for beta.bmi                               5.240   NA\n\nMarginal log-Likelihood:  -367.34 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"
  },
  {
    "objectID": "simulation_example.html",
    "href": "simulation_example.html",
    "title": "Simulation example",
    "section": "",
    "text": "\\[\n\\def\\na{\\texttt{NA}}\n\\]\nWe here provide a detailed guide to the data simulation and measurement error model used in the simulation study in the paper. This vignette goes through the model in great detail, but only one data set is generated. In the example Simulation study the simulation is run 100 times to ensure that the result are not just due to random variation.\nFor this example, we simulate a linear regression model with a mismeasured covariate \\(\\boldsymbol{x}\\), observed as \\(\\boldsymbol{w}\\), as well as a covariate without measurement error, \\(\\boldsymbol{z}\\). The covariate \\(\\boldsymbol{x}\\) is constructed to have both Berkson and classical measurement error, and it is also missing (completely at random) approximately 20% of the observations."
  },
  {
    "objectID": "simulation_example.html#data-generation",
    "href": "simulation_example.html#data-generation",
    "title": "Simulation example",
    "section": "Data generation",
    "text": "Data generation\nThe data is generated in the following code.\n\nset.seed(2022)\nn <- 1000\n\n# Covariate without error:\nz <- rnorm(n, mean = 0, sd = 1)\n\n# Berkson error:\nr <- rnorm(n, mean = 1 + 2*z, sd = 1)\nu_b <- rnorm(n, sd = 1)\nx <- r + u_b\n\n# Response:\ny <- 1 + 2*x + 2*z + rnorm(n)\n\n# Classical error:\nu_c <- rnorm(n, sd = 1)\nw <- r + u_c \n\n# Missingness:\nm_pred <- -1.5 - 0.5*z # This gives a mean probability of missing of ca 0.2.\nm_prob <- exp(m_pred)/(1 + exp(m_pred))\n\nm_index <- rbinom(n, 1, prob = m_prob) # MAR\n# m_index <- sample(1:n, 0.2*n, replace = FALSE) # MCAR\nw[m_index] <- NA\n\nsimulated_data <- data.frame(y = y, w = w, z = z)\n\nThe simulated “observed” data then consists of three columns:\n\\[\n\\boldsymbol{y} \\quad \\boldsymbol{w} \\quad \\boldsymbol{z}\n\\]\nFor \\(n = 1000\\) simulated observations, they contain:\n\n\\(y_1, \\dots, y_n\\): The continuous response.\n\\(w_1, \\dots, w_n\\): A continuous covariate with classical and Berkson measurement error and missing values.\n\\(z_1, \\dots, z_n\\): A continuous covariate without measurement error or missingness.\n\n\nattach(simulated_data)\nn <- nrow(simulated_data)"
  },
  {
    "objectID": "simulation_example.html#model",
    "href": "simulation_example.html#model",
    "title": "Simulation example",
    "section": "Model",
    "text": "Model\nOur response for this model will be\n\\[\n\\boldsymbol{y} = \\beta_0 + \\beta_x \\boldsymbol{x} + \\beta_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon} \\ , \\quad \\boldsymbol{\\varepsilon} \\sim N(\\boldsymbol{0}, \\tau_y\\boldsymbol{I}) \\ ,\n\\] the Berkson error model is \\[\n  \\boldsymbol{x} = \\boldsymbol{r} + \\boldsymbol{u}_b \\ , \\quad \\boldsymbol{u}_b \\sim N(\\boldsymbol{0}, \\tau_{u_b}\\boldsymbol{I}) \\ ,\n\\] the classical error model is \\[\n  \\boldsymbol{w} = \\boldsymbol{r} + \\boldsymbol{u}_c \\ , \\quad \\boldsymbol{u}_c \\sim N(\\boldsymbol{0}, \\tau_{u_c}\\boldsymbol{I}) \\ ,\n\\] and the imputation model is \\[\n\\boldsymbol{r} = \\alpha_0 + \\alpha_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon}_r \\ , \\quad \\boldsymbol{\\varepsilon}_r \\sim N(\\boldsymbol{0}, \\tau_r\\boldsymbol{I}) \\ .\n\\] Rewritten for INLA these models are \\[\n\\begin{align}\n  \\boldsymbol{y} &= \\beta_0 + \\beta_x \\boldsymbol{x} + \\beta_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon} \\ , \\quad &\\boldsymbol{\\varepsilon} \\sim N(\\boldsymbol{0}, \\tau_y\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{0} &= -\\boldsymbol{x} + \\boldsymbol{r} + \\boldsymbol{u}_b \\ , \\quad & \\boldsymbol{u}_b \\sim N(\\boldsymbol{0}, \\tau_{u_b}\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{w} &= \\boldsymbol{r} + \\boldsymbol{u}_c \\ , \\quad &\\boldsymbol{u}_c \\sim N(\\boldsymbol{0}, \\tau_{u_c}\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{0} &= -\\boldsymbol{r} + \\alpha_0 + \\alpha_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon}_r \\ , \\quad &\\boldsymbol{\\varepsilon}_r \\sim N(\\boldsymbol{0}, \\tau_r\\boldsymbol{I}) \\ .\n\\end{align}\n\\]\nThe prior distributions are\n\n\\(\\boldsymbol{r} \\sim N(\\alpha_0 + \\alpha_z \\boldsymbol{z}, \\tau_r \\boldsymbol{I})\\),\n\\(\\beta_0, \\beta_x, \\beta_z \\sim N(0, \\tau_{\\beta})\\), with \\(\\tau_{\\beta} = 0.001\\),\n\\(\\alpha_0, \\alpha_z \\sim N(0, \\tau_{\\alpha})\\), with \\(\\tau_{\\alpha} = 0.0001\\)\n\\(\\tau_{y}, \\tau_{u_b}, \\tau_{u_c}, \\tau_{r} \\sim \\text{Gamma}(0.5, 0.5)\\),\n\nWe specify the priors in the code:\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 1/1000) # N(0, 10^3)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1/10000) # N(0, 10^4)\n  \n# Priors for y, measurement error and true x-value precision\nprior.prec.y <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_b <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_c <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.r <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  \n# Initial values\nprec.y <- 1\nprec.u_b <- 1\nprec.u_c <- 1\nprec.r <- 1\n\nThe hierarchical model described in the above section is fit in INLA as a joint model using the \\(\\texttt{copy}\\) feature. We first specify the models in the following matrices and vectors:\n\\[\n\\underbrace{\n\\begin{bmatrix}\n  y_1 & \\na & \\na & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  y_n & \\na & \\na & \\na \\\\\n  \\na &  0  & \\na & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na &  0  & \\na & \\na \\\\\n  \\na & \\na & w_1 & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na & \\na & w_n & \\na \\\\\n  \\na & \\na & \\na &  0  \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na & \\na & \\na &  0  \\\\\n\\end{bmatrix}\n}_{\\texttt{Y}}\n=\n\\beta_0\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.0}}\n+ \\beta_x\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\vdots \\\\\nn \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.x}}\n+\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n-1 \\\\\n\\vdots \\\\\n-n \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{id.x}}\n+\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n1 \\\\\n\\vdots \\\\\nn \\\\\n1 \\\\\n\\vdots \\\\\nn \\\\\n-1 \\\\\n\\vdots \\\\\n-n \\\\\n\\end{bmatrix}\n}_{\\texttt{id.r}}\n+ \\beta_z\n\\underbrace{\n\\begin{bmatrix}\nz_1 \\\\\n\\vdots \\\\\nz_n \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.z}}\n+ \\alpha_0\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{bmatrix}\n}_{\\texttt{alpha.0}}\n+ \\alpha_z\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\nz_1 \\\\\n\\vdots \\\\\nz_n \\\\\n\\end{bmatrix}\n}_{\\texttt{alpha.z}}\n\\]\nWe specify these matrices in our code:\n\nY <- matrix(NA, 4*n, 4)\n\nY[1:n, 1] <- y                   # Regression model of interest response\nY[n+(1:n), 2] <- rep(0, n)       # Berkson error model response\nY[2*n+(1:n), 3] <- w             # Classical error model response\nY[3*n+(1:n), 4] <- rep(0, n)     # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, 3*n))\nbeta.x <- c(1:n, rep(NA, 3*n))\nbeta.z <- c(z, rep(NA, 3*n))\n\nid.x <- c(rep(NA, n), 1:n, rep(NA, n), rep(NA, n))\nweight.x <- c(rep(NA, n), rep(-1, n), rep(NA, n), rep(NA, n))\n\nid.r <- c(rep(NA, n), 1:n, 1:n, 1:n)\nweight.r <- c(rep(NA, n), rep(1, n), rep(1, n), rep(-1, n))\n\nalpha.0 = c(rep(NA, 3*n), rep(1, n))\nalpha.z = c(rep(NA, 3*n), z)\n\n\ndd <- list(Y = Y,\n           beta.0 = beta.0,\n           beta.x = beta.x,\n           beta.z = beta.z,\n           id.x = id.x, \n           weight.x = weight.x,\n           id.r = id.r,\n           weight.r = weight.r,\n           alpha.0 = alpha.0,\n           alpha.z = alpha.z)\n\nNext, we set up the INLA formula. There are four fixed effects (\\(\\beta_0\\), \\(\\beta_z\\), \\(\\alpha_0\\), \\(\\alpha_z\\)) and three random effects. Two of the random effects are necessary to ensure that the values of \\(\\boldsymbol{r}\\) are the same in the exposure model and error model are assigned the same values as in the regression model, where \\(\\beta_x \\boldsymbol{r}\\) is the product of two unknown quantities. The third random effect term is for encoding the Berkson error model.\n\nf(beta.x, copy=\"id.x\", ...): The copy=\"id.x\" argument ensures that identical values are assigned to \\(\\boldsymbol{x}\\) in all components of the joint model. \\(\\beta_x\\), which is treated as a hyperparameter, is the scaling parameter of the copied process \\(\\boldsymbol{x}^*\\).\nf(id.x, weight.x, ...): id.x contains the \\(\\boldsymbol{x}\\)-values, encoded as an i.i.d. Gaussian random effect, and weighted with weight.x to ensure the correct signs in the joint model. The values option contains the vector of all values assumes by the covariate for which the effect is estimated. The precision prec of the random effect is fixed at \\(\\exp(-15)\\), which is necessary since the uncertainty in \\(\\boldsymbol{x}\\) is already modeled in the second level (column 2 of Y) of the joint model, which defines the imputation component.\nf(id.r, weight.r, ...): in the same way that id.x, contains the \\(\\boldsymbol{x}\\)-values, id.r contains the \\(\\boldsymbol{r}\\)-values.\n\n\nformula = Y ~ - 1 + beta.0 + beta.z +\n  f(beta.x, copy = \"id.x\",  \n    hyper = list(beta = list(param = prior.beta, fixed = FALSE))) +\n  f(id.x, weight.x, model = \"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed = TRUE))) +\n  f(id.r, weight.r, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed = TRUE))) + \n  alpha.0 + alpha.z\n\nWe explicitly remove the intercept using -1 since there is no common intercept in the joint model, and the model specific intercepts \\(\\beta_0\\) and \\(\\alpha_0\\) are specified instead.\nNext comes the call of the inla function. We explain further some of the terms:\n\nfamily: Here we need to specify one likelihood function for each of the model levels corresponding to each column in the matrix Y. In this case, they are all Gaussian, but if we for instance had a logistic regression model as our model of interest, then the list would be c(\"binomial\", \"gaussian\", \"gaussian\", \"gaussian\").\ncontrol.family: Here we specify the hyperparameters for each of the three likelihoods. In this case, we specify the precision for each Gaussian likelihood, \\(\\tau_y\\), \\(\\tau_{u_b}\\), \\(\\tau_{u_c}\\) and \\(\\tau_{r}\\), respectively.\ncontrol.predictor: Computes the predictive distribution of the missing observations in the response (TODO: does this mean w in this case? Since w is the response for one of the models?)\ncontrol.fixed: Prior specification for the fixed effects.\n\n\nmodel_sim <- inla(formula, data = dd, scale = scale.vec,\n                  family = c(\"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\"),\n                  control.family = list(\n                    list(hyper = list(prec = list(initial = log(prec.y),\n                                                  param = prior.prec.y,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.u_b),\n                                                  param = prior.prec.u_b,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.u_c),\n                                                  param = prior.prec.u_c,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.r),\n                                                  param = prior.prec.r,\n                                                  fixed = FALSE)))\n                  ),\n                  control.predictor = list(compute = TRUE), \n                  control.fixed = list(\n                    mean = list(beta.0 = prior.beta[1],\n                                beta.z = prior.beta[1],\n                                alpha.0 = prior.alpha[1],\n                                alpha.z = prior.alpha[1]),\n                    prec = list(beta.0 = prior.beta[2],\n                                beta.z = prior.beta[2],\n                                alpha.0 = prior.alpha[2],\n                                alpha.z = prior.alpha[2]))\n               )"
  },
  {
    "objectID": "simulation_example.html#results",
    "href": "simulation_example.html#results",
    "title": "Simulation example",
    "section": "Results",
    "text": "Results\n\n# Summary of fixed effects:\nfixed <- model_sim$summary.fixed[1:5]\nfixed[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n\n            mean 0.025quant 0.975quant\nbeta.0  1.030390  0.6528240   1.338318\nbeta.z  2.123489  1.4632119   2.628708\nalpha.0 1.014109  0.9262175   1.101999\nalpha.z 2.008122  1.9200374   2.096205\n\n# Summary of random effects:\nhyper <- model_sim$summary.hyperpar[1:5]\nhyper[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n\n                                                mean 0.025quant 0.975quant\nPrecision for the Gaussian observations    0.9432112  0.6121326   1.722205\nPrecision for the Gaussian observations[2] 1.0421744  0.6998576   1.573373\nPrecision for the Gaussian observations[3] 1.1385433  0.9312267   1.352441\nPrecision for the Gaussian observations[4] 0.8956919  0.7873540   1.032751\nBeta for beta.x                            1.9318527  1.6882794   2.206946\n\n\nThe fixed effects can then be accessed through model$summary.fixed, whereas the posterior mean and sd for the coefficient of \\(\\boldsymbol{x}\\) can be accessed through model$summary.hyperpar, since \\(\\beta_x\\) is actually a hyperparameter of the model. In model$summary.hyperpar we also get the precision terms for each of the sub-models in the order they have been defined, so the first precision is \\(\\tau_y\\), the second one \\(\\tau_{u_b}\\), the third one \\(\\tau_{u_c}\\) and the final one is \\(\\tau_r\\)."
  }
]