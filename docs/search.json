[
  {
    "objectID": "simulation_example.html",
    "href": "simulation_example.html",
    "title": "Simulation example",
    "section": "",
    "text": "\\[\n\\def\\na{\\texttt{NA}}\n\\]\nWe here provide a detailed guide to the data simulation and measurement error model used in the simulation study in the paper. This vignette goes through the model in great detail, but only one data set is generated. In the example Simulation study the simulation is run 100 times to ensure that the result are not just due to random variation.\nFor this example, we simulate a linear regression model with a mismeasured covariate \\(\\boldsymbol{x}\\), observed as \\(\\boldsymbol{w}\\), as well as a covariate without measurement error, \\(\\boldsymbol{z}\\). The covariate \\(\\boldsymbol{x}\\) is constructed to have both Berkson and classical measurement error, and it is also missing (completely at random) approximately 20% of the observations."
  },
  {
    "objectID": "simulation_example.html#data-generation",
    "href": "simulation_example.html#data-generation",
    "title": "Simulation example",
    "section": "Data generation",
    "text": "Data generation\nThe data is generated in the following code.\n\nset.seed(2022)\nn <- 1000\n\n# Covariate without error:\nz <- rnorm(n, mean = 0, sd = 1)\n\n# Berkson error:\nu_b <- rnorm(n, sd = 1)\nr <- rnorm(n, mean = 1 + 2*z, sd = 1)\nx <- r + u_b\n\n# Response:\ny <- 1 + 2*x + 2*z + rnorm(n)\n\n# Classical error:\nu_c <- rnorm(n, sd = 1)\nw <- r + u_c \n\n# Missingness:\nm_pred <- -1.5 - 0.5*z # This gives a mean probability of missing of ca 0.2.\nm_prob <- exp(m_pred)/(1 + exp(m_pred))\n\nm_index <- as.logical(rbinom(n, 1, prob = m_prob)) # MAR\n# m_index <- sample(1:n, 0.2*n, replace = FALSE) # MCAR\nw[m_index] <- NA\n\nsimulated_data <- data.frame(y = y, w = w, z = z)\n\n\n\n\nThe simulated “observed” data then consists of three columns:\n\\[\n\\boldsymbol{y} \\quad \\boldsymbol{w} \\quad \\boldsymbol{z}\n\\]\nFor \\(n = 1000\\) simulated observations, they contain:\n\n\\(y_1, \\dots, y_n\\): The continuous response.\n\\(w_1, \\dots, w_n\\): A continuous covariate with classical and Berkson measurement error and missing values.\n\\(z_1, \\dots, z_n\\): A continuous covariate without measurement error or missingness.\n\n\nattach(simulated_data)\nn <- nrow(simulated_data)"
  },
  {
    "objectID": "simulation_example.html#model",
    "href": "simulation_example.html#model",
    "title": "Simulation example",
    "section": "Model",
    "text": "Model\nOur response for this model will be\n\\[\n\\boldsymbol{y} = \\beta_0 + \\beta_x \\boldsymbol{x} + \\beta_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon} \\ , \\quad \\boldsymbol{\\varepsilon} \\sim N(\\boldsymbol{0}, \\tau_y\\boldsymbol{I}) \\ ,\n\\] the Berkson error model is \\[\n  \\boldsymbol{x} = \\boldsymbol{r} + \\boldsymbol{u}_b \\ , \\quad \\boldsymbol{u}_b \\sim N(\\boldsymbol{0}, \\tau_{u_b}\\boldsymbol{I}) \\ ,\n\\] the classical error model is \\[\n  \\boldsymbol{w} = \\boldsymbol{r} + \\boldsymbol{u}_c \\ , \\quad \\boldsymbol{u}_c \\sim N(\\boldsymbol{0}, \\tau_{u_c}\\boldsymbol{I}) \\ ,\n\\] and the imputation model is \\[\n\\boldsymbol{r} = \\alpha_0 + \\alpha_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon}_r \\ , \\quad \\boldsymbol{\\varepsilon}_r \\sim N(\\boldsymbol{0}, \\tau_r\\boldsymbol{I}) \\ .\n\\] Rewritten for INLA these models are \\[\n\\begin{align}\n  \\boldsymbol{y} &= \\beta_0 + \\beta_x \\boldsymbol{x} + \\beta_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon} \\ , \\quad &\\boldsymbol{\\varepsilon} \\sim N(\\boldsymbol{0}, \\tau_y\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{0} &= -\\boldsymbol{x} + \\boldsymbol{r} + \\boldsymbol{u}_b \\ , \\quad & \\boldsymbol{u}_b \\sim N(\\boldsymbol{0}, \\tau_{u_b}\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{w} &= \\boldsymbol{r} + \\boldsymbol{u}_c \\ , \\quad &\\boldsymbol{u}_c \\sim N(\\boldsymbol{0}, \\tau_{u_c}\\boldsymbol{I}) \\ , \\\\\n  \\boldsymbol{0} &= -\\boldsymbol{r} + \\alpha_0 + \\alpha_z \\boldsymbol{z} + \\boldsymbol{\\varepsilon}_r \\ , \\quad &\\boldsymbol{\\varepsilon}_r \\sim N(\\boldsymbol{0}, \\tau_r\\boldsymbol{I}) \\ .\n\\end{align}\n\\]\nThe prior distributions are\n\n\\(\\boldsymbol{r} \\sim N(\\alpha_0 + \\alpha_z \\boldsymbol{z}, \\tau_r \\boldsymbol{I})\\),\n\\(\\beta_0, \\beta_x, \\beta_z \\sim N(0, \\tau_{\\beta})\\), with \\(\\tau_{\\beta} = 0.001\\),\n\\(\\alpha_0, \\alpha_z \\sim N(0, \\tau_{\\alpha})\\), with \\(\\tau_{\\alpha} = 0.0001\\)\n\\(\\tau_{y}, \\tau_{u_b}, \\tau_{u_c}, \\tau_{r} \\sim \\text{Gamma}(0.5, 0.5)\\),\n\nWe specify the priors in the code:\n\n# Priors for model of interest coefficients\nprior.beta <- c(0, 1/1000) # N(0, 10^3)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1/10000) # N(0, 10^4)\n  \n# Priors for y, measurement error and true x-value precision\nprior.prec.y <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_b <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_c <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.r <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  \n# Initial values\nprec.y <- 1\nprec.u_b <- 1\nprec.u_c <- 1\nprec.r <- 1\n\nThe hierarchical model described in the above section is fit in INLA as a joint model using the \\(\\texttt{copy}\\) feature. We first specify the models in the following matrices and vectors:\n\\[\n\\underbrace{\n\\begin{bmatrix}\n  y_1 & \\na & \\na & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  y_n & \\na & \\na & \\na \\\\\n  \\na &  0  & \\na & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na &  0  & \\na & \\na \\\\\n  \\na & \\na & w_1 & \\na \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na & \\na & w_n & \\na \\\\\n  \\na & \\na & \\na &  0  \\\\\n  \\vdots & \\vdots & \\vdots & \\vdots \\\\\n  \\na & \\na & \\na &  0  \\\\\n\\end{bmatrix}\n}_{\\texttt{Y}}\n=\n\\beta_0\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.0}}\n+ \\beta_x\n\\underbrace{\n\\begin{bmatrix}\n1 \\\\\n\\vdots \\\\\nn \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.x}}\n+\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n-1 \\\\\n\\vdots \\\\\n-n \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{id.x}}\n+\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n1 \\\\\n\\vdots \\\\\nn \\\\\n1 \\\\\n\\vdots \\\\\nn \\\\\n-1 \\\\\n\\vdots \\\\\n-n \\\\\n\\end{bmatrix}\n}_{\\texttt{id.r}}\n+ \\beta_z\n\\underbrace{\n\\begin{bmatrix}\nz_1 \\\\\n\\vdots \\\\\nz_n \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\end{bmatrix}\n}_{\\texttt{beta.z}}\n+ \\alpha_0\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n1 \\\\\n\\vdots \\\\\n1 \\\\\n\\end{bmatrix}\n}_{\\texttt{alpha.0}}\n+ \\alpha_z\n\\underbrace{\n\\begin{bmatrix}\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\n\\na \\\\\n\\vdots \\\\\n\\na \\\\\nz_1 \\\\\n\\vdots \\\\\nz_n \\\\\n\\end{bmatrix}\n}_{\\texttt{alpha.z}}\n\\]\nWe specify these matrices in our code:\n\nY <- matrix(NA, 4*n, 4)\n\nY[1:n, 1] <- y                   # Regression model of interest response\nY[n+(1:n), 2] <- rep(0, n)       # Berkson error model response\nY[2*n+(1:n), 3] <- w             # Classical error model response\nY[3*n+(1:n), 4] <- rep(0, n)     # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, 3*n))\nbeta.x <- c(1:n, rep(NA, 3*n))\nbeta.z <- c(z, rep(NA, 3*n))\n\nid.x <- c(rep(NA, n), 1:n, rep(NA, n), rep(NA, n))\nweight.x <- c(rep(NA, n), rep(-1, n), rep(NA, n), rep(NA, n))\n\nid.r <- c(rep(NA, n), 1:n, 1:n, 1:n)\nweight.r <- c(rep(NA, n), rep(1, n), rep(1, n), rep(-1, n))\n\nalpha.0 <- c(rep(NA, 3*n), rep(1, n))\nalpha.z <- c(rep(NA, 3*n), z)\n\n\ndd <- list(Y = Y,\n           beta.0 = beta.0,\n           beta.x = beta.x,\n           beta.z = beta.z,\n           id.x = id.x, \n           weight.x = weight.x,\n           id.r = id.r,\n           weight.r = weight.r,\n           alpha.0 = alpha.0,\n           alpha.z = alpha.z)\n\nNext, we set up the INLA formula. There are four fixed effects (\\(\\beta_0\\), \\(\\beta_z\\), \\(\\alpha_0\\), \\(\\alpha_z\\)) and three random effects. Two of the random effects are necessary to ensure that the values of \\(\\boldsymbol{r}\\) are the same in the exposure model and error model are assigned the same values as in the regression model, where \\(\\beta_x \\boldsymbol{r}\\) is the product of two unknown quantities. The third random effect term is for encoding the Berkson error model.\n\nf(beta.x, copy=\"id.x\", ...): The copy=\"id.x\" argument ensures that identical values are assigned to \\(\\boldsymbol{x}\\) in all components of the joint model. \\(\\beta_x\\), which is treated as a hyperparameter, is the scaling parameter of the copied process \\(\\boldsymbol{x}^*\\).\nf(id.x, weight.x, ...): id.x contains the \\(\\boldsymbol{x}\\)-values, encoded as an i.i.d. Gaussian random effect, and weighted with weight.x to ensure the correct signs in the joint model. The values option contains the vector of all values assumes by the covariate for which the effect is estimated. The precision prec of the random effect is fixed at \\(\\exp(-15)\\), which is necessary since the uncertainty in \\(\\boldsymbol{x}\\) is already modeled in the second level (column 2 of Y) of the joint model, which defines the imputation component.\nf(id.r, weight.r, ...): in the same way that id.x, contains the \\(\\boldsymbol{x}\\)-values, id.r contains the \\(\\boldsymbol{r}\\)-values.\n\n\nformula <- Y ~ - 1 + beta.0 + beta.z +\n  f(beta.x, copy = \"id.x\",  \n    hyper = list(beta = list(param = prior.beta, fixed = FALSE))) +\n  f(id.x, weight.x, model = \"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed = TRUE))) +\n  f(id.r, weight.r, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed = TRUE))) + \n  alpha.0 + alpha.z\n\nWe explicitly remove the intercept using -1 since there is no common intercept in the joint model, and the model specific intercepts \\(\\beta_0\\) and \\(\\alpha_0\\) are specified instead.\nNext comes the call of the inla function. We explain further some of the terms:\n\nfamily: Here we need to specify one likelihood function for each of the model levels corresponding to each column in the matrix Y. In this case, they are all Gaussian, but if we for instance had a logistic regression model as our model of interest, then the list would be c(\"binomial\", \"gaussian\", \"gaussian\", \"gaussian\").\ncontrol.family: Here we specify the hyperparameters for each of the three likelihoods. In this case, we specify the precision for each Gaussian likelihood, \\(\\tau_y\\), \\(\\tau_{u_b}\\), \\(\\tau_{u_c}\\) and \\(\\tau_{r}\\), respectively.\ncontrol.predictor: Computes the predictive distribution of the missing observations in the response.\ncontrol.fixed: Prior specification for the fixed effects.\n\n\nmodel_sim <- inla(formula, data = dd,\n                  family = c(\"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\"),\n                  control.family = list(\n                    list(hyper = list(prec = list(initial = log(prec.y),\n                                                  param = prior.prec.y,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.u_b),\n                                                  param = prior.prec.u_b,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.u_c),\n                                                  param = prior.prec.u_c,\n                                                  fixed = FALSE))),\n                    list(hyper = list(prec = list(initial = log(prec.r),\n                                                  param = prior.prec.r,\n                                                  fixed = FALSE)))\n                  ),\n                  control.predictor = list(compute = TRUE), \n                  control.fixed = list(\n                    mean = list(beta.0 = prior.beta[1],\n                                beta.z = prior.beta[1],\n                                alpha.0 = prior.alpha[1],\n                                alpha.z = prior.alpha[1]),\n                    prec = list(beta.0 = prior.beta[2],\n                                beta.z = prior.beta[2],\n                                alpha.0 = prior.alpha[2],\n                                alpha.z = prior.alpha[2]))\n               )"
  },
  {
    "objectID": "simulation_example.html#results",
    "href": "simulation_example.html#results",
    "title": "Simulation example",
    "section": "Results",
    "text": "Results\n\n# Summary of fixed effects:\nfixed <- model_sim$summary.fixed[1:5]\nfixed[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n\n            mean 0.025quant 0.975quant\nbeta.0  1.045890  0.6562144   1.372191\nbeta.z  2.157892  1.4764692   2.676830\nalpha.0 1.005302  0.9123583   1.098251\nalpha.z 1.987672  1.8916031   2.083756\n\n# Summary of random effects:\nhyper <- model_sim$summary.hyperpar[1:5]\nhyper[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n\n                                                mean 0.025quant 0.975quant\nPrecision for the Gaussian observations    0.6573104  0.4748465  0.6681521\nPrecision for the Gaussian observations[2] 1.4160039  1.1534509 11.2367339\nPrecision for the Gaussian observations[3] 1.0216925  0.9021679  1.0810789\nPrecision for the Gaussian observations[4] 1.0364528  0.9792048  1.9582454\nBeta for beta.x                            2.1149641  2.0095097  3.2729965\n\n\nThe fixed effects can then be accessed through model$summary.fixed, whereas the posterior mean and sd for the coefficient of \\(\\boldsymbol{x}\\) can be accessed through model$summary.hyperpar, since \\(\\beta_x\\) is actually a hyperparameter of the model. In model$summary.hyperpar we also get the precision terms for each of the sub-models in the order they have been defined, so the first precision is \\(\\tau_y\\), the second one \\(\\tau_{u_b}\\), the third one \\(\\tau_{u_c}\\) and the final one is \\(\\tau_r\\)."
  },
  {
    "objectID": "simulation_study.html",
    "href": "simulation_study.html",
    "title": "Simulation study",
    "section": "",
    "text": "library(INLA)\nlibrary(inlabru)\nlibrary(tidyverse)\nIn the vignette Simulation example, we simulate a single data set with Berkson error, classical error and missing data, and then fit a measurement error model to adjust for these errors. In this simulation study, we do the exact same steps, but repeated on 100 simulated data sets instead of just one, to ensure that the results are not an artifact of one particular data set. This vignette consists of mostly just code, for detailed explanations on the steps taken in the analysis, please refer to Simulation example."
  },
  {
    "objectID": "simulation_study.html#setting-up-functions",
    "href": "simulation_study.html#setting-up-functions",
    "title": "Simulation study",
    "section": "Setting up functions",
    "text": "Setting up functions\n\nFunction for simulating data\n\nsimulate_data <- function(n){\n  # Covariate without error:\n  z <- rnorm(n, mean = 0, sd = 1)\n  \n  # Berkson error:\n  u_b <- rnorm(n)\n  r <- rnorm(n, mean = 1 + 2*z, sd = 1)\n  x <- r + u_b\n  \n  # Response:\n  y <- 1 + 2*x + 2*z + rnorm(n)\n  \n  # Classical error:\n  u_c <- rnorm(n)\n  w <- r + u_c \n  \n  # Missingness:\n  m_pred <- -1.5 - 0.5*z # MAR. This gives a mean probability of missing of ca 0.2.\n  # m_pred <- -1.5 - 0.5*x # MNAR\n  m_prob <- exp(m_pred)/(1 + exp(m_pred))\n  m_index <- as.logical(rbinom(n, 1, prob = m_prob)) # MAR/MNAR\n  # m_index <- sample(1:n, 0.2*n, replace = FALSE) # MCAR\n  w[m_index] <- NA\n\n  simulated_data <- data.frame(y = y, w = w, z = z, x = x)\n  return(simulated_data)\n}\n\n\n\nFunctions for setting up the model matrices\n\n# Make matrix for ME model\nmake_matrix_ME <- function(data){\n  n <- nrow(data)\n  \n  y <- data$y\n  w <- data$w\n  z <- data$z\n  \n  Y <- matrix(NA, 4*n, 4)\n\n  Y[1:n, 1] <- y                 # Regression model of interest response\n  Y[n+(1:n), 2] <- rep(0, n)     # Berkson error model response\n  Y[2*n+(1:n), 3] <- w           # Classical error model response\n  Y[3*n+(1:n), 4] <- rep(0, n)   # Imputation model response\n\n  beta.0 <- c(rep(1, n), rep(NA, 3*n))\n  beta.x <- c(1:n, rep(NA, 3*n))\n  beta.z <- c(z, rep(NA, 3*n))\n\n  id.x <- c(rep(NA, n), 1:n, rep(NA, n), rep(NA, n))\n  weight.x <- c(rep(NA, n), rep(-1, n), rep(NA, n), rep(NA, n))\n\n  id.r <- c(rep(NA, n), 1:n, 1:n, 1:n)\n  weight.r <- c(rep(NA, n), rep(1, n), rep(1, n), rep(-1, n))\n\n  alpha.0 = c(rep(NA, 3*n), rep(1, n))\n  alpha.z = c(rep(NA, 3*n), z)\n  \n  dd_adj <- list(Y = Y,\n                       beta.0 = beta.0,\n                       beta.x = beta.x,\n                       beta.z = beta.z,\n                       id.x = id.x, \n                       weight.x = weight.x,\n                       id.r = id.r,\n                       weight.r = weight.r,\n                       alpha.0 = alpha.0,\n                       alpha.z = alpha.z)\n\n  return(dd_adj)\n}\n\n# Make matrix for naive model\nmake_matrix_naive <- function(data){\n  y <- data$y\n  w <- data$w\n  z <- data$z\n  \n  # Naive model\n  dd_naive <- list(Y = y,\n                         beta.0 = rep(1, nrow(data)),\n                         beta.x = w, \n                         beta.z = z)\n  return(dd_naive)\n}\n\n# Make matrix for model using the unobserved variable\nmake_matrix_true <- function(data){\n  y <- data$y\n  x <- data$x\n  z <- data$z\n  # True model\n  dd_naive <- list(Y = y,\n                         beta.0 = rep(1, nrow(data)),\n                         beta.x = x, \n                         beta.z = z)\n}\n\n\n\nFunction for fitting the ME model\n\n# Fit ME model\nfit_model_ME <- function(data_matrix) {\n  # Priors for model of interest coefficients\n  prior.beta <- c(0, 1/1000) # N(0, 10^3)\n  \n  # Priors for exposure model coefficients\n  prior.alpha <- c(0, 1/10000) # N(0, 10^4)\n  \n  # Priors for y, measurement error and true x-value precision\n  prior.prec.y <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  prior.prec.u_b <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  prior.prec.u_c <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  prior.prec.r <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  \n  # Initial values\n  prec.y <- 1\n  prec.u_b <- 1\n  prec.u_c <- 1\n  prec.r <- 1\n  \n  # Formula\n  formula = Y ~ - 1 + beta.0 + beta.z +\n    f(beta.x, copy = \"id.x\",  \n      hyper = list(beta = list(param = prior.beta, fixed = FALSE))) +\n    f(id.x, weight.x, model = \"iid\", values = 1:n, \n      hyper = list(prec = list(initial = -15, fixed = TRUE))) +\n    f(id.r, weight.r, model=\"iid\", values = 1:n, \n      hyper = list(prec = list(initial = -15, fixed = TRUE))) + \n    alpha.0 + alpha.z\n  \n  # Fit model\n  model <- inla(formula,\n                data = data_matrix,\n                family = c(\"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\"),\n                control.family = list(\n                  list(hyper = list(prec = list(initial = log(prec.y), \n                                                param = prior.prec.y, \n                                                fixed = FALSE))), \n                  list(hyper = list(prec = list(initial = log(prec.u_b),\n                                                param = prior.prec.u_b,\n                                                fixed = FALSE))),\n                  list(hyper = list(prec = list(initial = log(prec.u_c), \n                                                param = prior.prec.u_c, \n                                                fixed = FALSE))), \n                  list(hyper = list(prec = list(initial = log(prec.r), \n                                                param = prior.prec.r, \n                                                fixed = FALSE)))), \n                control.predictor = list(compute = TRUE), \n                control.fixed = list(\n                  mean = list(\n                    beta.0 = prior.beta[1],\n                    beta.z = prior.beta[1],\n                    alpha.0 = prior.alpha[1],\n                    alpha.z = prior.alpha[1]),\n                  prec = list(\n                    beta.0 = prior.beta[2],\n                    beta.z = prior.beta[2],\n                    alpha.0 = prior.alpha[2],\n                    alpha.z = prior.alpha[2])\n    )\n  )\n}\n\n\n\nFunction for fitting the true/naive model\nThe same function can be used to fit the naive model (y ~ w + z) and the best-case model (y ~ x + z) since they simply differ in the variable that is inputted (w versus x).\n\nfit_model_naive_true <- function(data_matrix){\n  # Priors for model of interest coefficients\n  prior.beta <- c(0, 1/1000) # N(0, 10^3)\n\n  # Priors for y, measurement error and true x-value precision\n  prior.prec.y <- c(0.5, 0.5) # Gamma(0.5, 0.5)\n  \n  # Initial values\n  prec.y <- 1\n\n  # Formula\n  formula <- Y ~ beta.0 - 1 + beta.x + beta.z\n  \n  # Fit model\n  model <- inla(formula,\n                data = data_matrix,\n                family = c(\"gaussian\"),\n                control.family = list(\n                  list(hyper = list(prec = list(initial = log(prec.y), \n                                                param = prior.prec.y, \n                                                fixed = FALSE)))),\n                control.fixed = list(\n                  mean = list(\n                    beta.0 = prior.beta[1],\n                    beta.z = prior.beta[1],\n                    beta.x = prior.beta[1]),\n                  prec = list(\n                    beta.0 = prior.beta[2],\n                    beta.z = prior.beta[2],\n                    beta.x = prior.beta[2])\n    )\n  )\n}"
  },
  {
    "objectID": "simulation_study.html#fitting-the-model-for-each-data-set",
    "href": "simulation_study.html#fitting-the-model-for-each-data-set",
    "title": "Simulation study",
    "section": "Fitting the model for each data set",
    "text": "Fitting the model for each data set\nWe simulate 100 data sets and fit the model that accounts for measurement error and missing data, and then save the posterior means for the intercept ans slopes.\nNote that this chunk may take a while to run.\n\nset.seed(1)\n\n# Number of iterations\nniter <- 100\n\n# Data frames to store the results \nresults_ME <- data.frame(matrix(NA, nrow=niter, ncol=5))\nnames(results_ME) <- c(\"beta.0\", \"beta.x\", \"beta.z\", \"alpha.0\", \"alpha.z\")\n\nresults_naive <- data.frame(matrix(NA, nrow=niter, ncol=3))\nnames(results_naive) <- c(\"beta.0\", \"beta.x\", \"beta.z\")\n\nresults_true <- data.frame(matrix(NA, nrow=niter, ncol=3))\nnames(results_true) <- c(\"beta.0\", \"beta.x\", \"beta.z\")\n\n\nfor(i in 1:niter){\n  n <- 1000\n  data <- simulate_data(n)\n  \n  # ME model\n  matrix_ME <- make_matrix_ME(data)\n  model_ME <- fit_model_ME(matrix_ME)\n  \n  # Naive model\n  matrix_naive <- make_matrix_naive(data)\n  model_naive <- fit_model_naive_true(matrix_naive)\n  \n  # True model\n  matrix_true <- make_matrix_true(data)\n  model_true <- fit_model_naive_true(matrix_true)\n  \n  results_ME[i, c(\"beta.0\", \"beta.z\", \n                  \"alpha.0\", \"alpha.z\")] <- t(model_ME$summary.fixed[\"mean\"])\n  results_ME[i, \"beta.x\"] <- model_ME$summary.hyperpar[\"Beta for beta.x\", \"mean\"]\n  \n  results_naive[i, c(\"beta.0\", \"beta.x\", \"beta.z\")] <- t(model_naive$summary.fixed[\"mean\"])\n  \n  results_true[i, c(\"beta.0\", \"beta.x\", \"beta.z\")] <- t(model_true$summary.fixed[\"mean\"])\n\n}"
  },
  {
    "objectID": "simulation_study.html#results",
    "href": "simulation_study.html#results",
    "title": "Simulation study",
    "section": "Results",
    "text": "Results\n\n\n\n\nsaveRDS(joint_results, file = \"results/simulation_results.rds\")\n\n\n\n\n\nlibrary(colorspace)\nlibrary(showtext)\nshowtext_auto()\n\n# Colors\ncol_bgr <- \"white\" #\"#fbf9f4\"\ncol_text <- \"#191919\"\ncolor_pal <- c(\"#004488\", \"#DDAA33\", \"#BB5566\")\n\n# Loading fonts\nf1 <- \"Open Sans\"\nfont_add_google(name = f1, family = f1)\n\nfont_size <- 20\n# Plot theme\ntheme_model_summary <- theme_minimal(base_size = font_size, base_family = f1) + \n  theme(\n  axis.title.y = element_blank(),\n  axis.title.x = element_text(size = 0.7*font_size, color = col_text, family = f1),\n  axis.text.y = element_text(size = 0.6*font_size, color = col_text, family = f1),\n  axis.text.x = element_text(size = 0.4*font_size, color = col_text, family = f1,\n                             margin = margin(0, 0, 1, 0)),\n  axis.ticks = element_blank(),\n  legend.title = element_blank(),\n  panel.background = element_rect(fill = col_bgr, color = col_bgr),\n  plot.background = element_rect(fill = col_bgr, color = col_bgr),\n  legend.position = \"none\",\n  strip.placement = \"outside\",\n  strip.text = element_text(color = col_text),\n  panel.grid.major.y = element_blank(),\n  panel.grid.minor.y = element_blank(),\n  panel.border = element_rect(color = \"grey65\", fill = NA, linewidth = 1), #\n  plot.title.position = \"plot\",\n  axis.line.x = element_line(linewidth = 1, color = \"grey65\"),#\n  plot.margin = margin(rep(15, 4))\n)\n\nggplot(simulation_results, aes(x = value, y = model, color = model)) +\n  # Invisible points to set limits\n  #geom_point(aes(x = upper), alpha = 0) +\n  #geom_point(aes(x = lower), alpha = 0) +\n  # Line going up from best case model\n  geom_segment(aes(x = true_value, xend = true_value), \n               y = \"Best case model\", yend = Inf, \n               color = \"grey30\", linetype = \"dotted\", size = 0.8) +\n  # Points for each run\n  geom_point(aes(fill = stage(model, after_scale = lighten(fill, 0.4))), \n             alpha = 0.7, size = 1.5, pch = 21, stroke = 0,\n             position = position_jitterdodge(jitter.width = 0.8, seed = 1)) +\n  # Error lines\n  stat_summary(geom = \"linerange\",\n               fun.min = function(z) {quantile(z, 0.025)},\n               fun.max = function(z) {quantile(z, 0.975)},\n               position = position_dodge(width = 0.75),\n               size = 1.3) +\n  # Point for mean\n  geom_point(aes(x = mean), size = 3) +\n  # Numeric text at mean\n  geom_text(aes(x = mean, \n                y = model, \n                label = format(round(mean, digits=2), nsmall = 2)), \n            vjust = -1.5, family = f1, size = 5, color = col_text) +\n  # Color for point and line\n  scale_color_manual(values = color_pal) +\n  scale_fill_manual(values = color_pal) +\n  # One plot for each variable\n  facet_wrap(vars(variable), \n             nrow = 1,\n             labeller = label_parsed, \n             scales = \"free_x\") +\n  # x-axis breaks\n  scale_x_continuous(breaks = seq(0, 4, 1)) +\n  # Lables\n  labs(x = \"Posterior mean\") +\n  # Add theme\n  theme_model_summary\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\nggsave(\"figures/simulation_boxplot.pdf\", \n       width = 10, height = 4, dpi = 600)\nggsave(\"figures/simulation_boxplot.eps\", width = 10, height = 4, dpi = 600, \n       device = cairo_ps)"
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html",
    "href": "missing_and_mismeasured_covariate.html",
    "title": "Missing and mismeasured covariate",
    "section": "",
    "text": "The data for this example is originally from the Third National Health and Nutrition Survey (NHANES III), but we use the data as pre-processed and provided by Bartlett and Keogh (2018). They linked the NHANES III data to data from the US National Death Index, with information about the mortality status of each participant in 2011. Following Keogh and Bartlett (2021), we consider a Weibull survival model with continuous covariates systolic blood pressure (SBP) and age, and binary covariates diabetes status, sex and smoking status. The response is time until death by cardiovascular disease. Deaths by other causes are treated as censorings.\nMeasurements of SBP are known to vary substantially within the same patient, and it is therefore measured twice for some participants, enabling us to estimate the variance of the error. However, for some participants there is only one measurement, and for others the SBP is completely missing. Note that the smoking status is also missing for around half of the participants, but since we only consider continuous ME, all observations with missingness in the (binary) smoking status are removed for this illustrative example, resulting in \\(n = 3433\\) observations.\nTo read more about how the Weibull hazard model is used in INLA in general, the documentation is very helpful."
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#packages",
    "href": "missing_and_mismeasured_covariate.html#packages",
    "title": "Missing and mismeasured covariate",
    "section": "Packages",
    "text": "Packages\n\nlibrary(survival)   # Survival modelling\nlibrary(INLA)       # Modelling\nlibrary(tidyverse)  # Data wrangling and visualisation\n\n\ninla.setOption(num.threads = \"1:1\")\n\nFunction for looking at relevant posterior estimates:\n\nview_relevant <- function(INLA_res, model_name){\n  fixed <- INLA_res$summary.fixed[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n  hyper <- INLA_res$summary.hyperpar[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n  relevant <- c(\"beta.age\", \"beta.diabetes\", \"beta.sex\", \"beta.smoke\")\n  \n  cat(model_name, \"\\n\")\n  beta.x <- hyper[nrow(hyper), ]\n  rownames(beta.x) <- \"beta.sbp\"\n  rbind(beta.x, fixed[relevant, ])\n}"
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#setting-up-the-data",
    "href": "missing_and_mismeasured_covariate.html#setting-up-the-data",
    "title": "Missing and mismeasured covariate",
    "section": "Setting up the data",
    "text": "Setting up the data\nWe load the data, and take a look at the first observations.\n\nfull_data <- read.csv(\"data/bloodpressure.csv\")\nhead(full_data)\n\n  X sbp1 sbp2 sex  age smoke diabetes d         t\n1 1   NA   NA   0 -0.3    NA        0 0 20.833336\n2 2  1.8   NA   0  1.2    NA        1 0  3.250000\n3 3  0.5   NA   0 -0.4    NA        1 0 20.416664\n4 4   NA   NA   1  0.0     1        0 0  4.083336\n5 5  0.5   NA   1 -0.7     1        0 0 12.000000\n6 6 -0.1   NA   1 -1.0     1        0 0 21.166664\n\n\nAs mentioned, we only consider measurement error and missing data in continuous covariates, so we remove the observations that have no recorded smoking status.\n\ndata <- full_data %>% drop_na(smoke)\nhead(data)\n\n   X sbp1 sbp2 sex  age smoke diabetes d         t\n1  4   NA   NA   1  0.0     1        0 0  4.083336\n2  5  0.5   NA   1 -0.7     1        0 0 12.000000\n3  6 -0.1   NA   1 -1.0     1        0 0 21.166664\n4 10  1.9   NA   1  2.0     0        0 0  3.250000\n5 13  1.1  0.3   1  0.2     0        0 0 13.666664\n6 14   NA   NA   0  0.7     0        0 1  5.833336"
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#complete-case-bayesian-analysis-using-inla",
    "href": "missing_and_mismeasured_covariate.html#complete-case-bayesian-analysis-using-inla",
    "title": "Missing and mismeasured covariate",
    "section": "Complete case Bayesian analysis using INLA",
    "text": "Complete case Bayesian analysis using INLA\nAs a baseline model to compare to the later models, we do a complete case analysis. For this naive analysis, only the observations that have a recorded sbp1 measurement are used.\n\nccdata <- data %>% drop_na(sbp1)\nn <- nrow(ccdata)\nhead(ccdata)\n\n   X sbp1 sbp2 sex  age smoke diabetes d        t\n1  5  0.5   NA   1 -0.7     1        0 0 12.00000\n2  6 -0.1   NA   1 -1.0     1        0 0 21.16666\n3 10  1.9   NA   1  2.0     0        0 0  3.25000\n4 13  1.1  0.3   1  0.2     0        0 0 13.66666\n5 15  0.8   NA   1  1.4     0        0 0  2.75000\n6 16 -0.6   NA   1 -0.1     0        0 0  2.50000\n\n\n\n# Note: JAGS and INLA use the same Weibull parameterization\n# (provided \"variant\" = 0 in INLA)\n\nformula.naive <- inla.surv(t/10, d) ~ sbp1 + sex + age + smoke + diabetes\n\nmodel_naive <- inla(formula.naive,\n                    family =\"weibullsurv\",\n                    data = ccdata,\n                    control.family = list(list(variant = 0)))\n\ncat(\"Naive model\")\n\nNaive model\n\nmodel_naive$summary.fixed[c(\"mean\", \"0.025quant\", \"0.975quant\")]\n\n                  mean  0.025quant 0.975quant\n(Intercept) -2.3611508 -2.55027441 -2.1786506\nsbp1         0.0852421  0.01318898  0.1560199\nsex          0.4872863  0.30313969  0.6759058\nage          0.8762591  0.76273395  0.9894474\nsmoke        0.2621554  0.06417933  0.4554144\ndiabetes     0.5032389  0.27969458  0.7178608"
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#measurement-error-models-in-inla",
    "href": "missing_and_mismeasured_covariate.html#measurement-error-models-in-inla",
    "title": "Missing and mismeasured covariate",
    "section": "Measurement error models in INLA",
    "text": "Measurement error models in INLA\nNext, we fit two measurement error models, first using only the complete cases for SBP1 (i.e, the same data set as for the previous complete case analysis), and next a measurement error model that uses all the SBP measurements, and thus both adjusts for the measurement error and the missingness.\n\nSpecifying priors (used in both ME models)\nThe priors are set up the same way as in Keogh and Bartlett (2018).\n\n# Priors for measurement error variance and true x-value\nprior.prec.u <- c(0.5, 0.5) # Gamma(0.5, 0.5) (same as Keogh&Bartlett)\nprior.prec.x <- c(0.5, 0.5) # Gamma(0.5, 0.5) (same as K&B)\n#prec.u = 1/sigma_uu\nprec.u <- 2.8\nprec.x = 1\n\n#curve(dgamma(x, shape = 0.5, rate = 0.5))\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1/10000) # N(0, 10^4) (same as K&B)\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 1/1000) # This has a Gaussian prior\n# (K&B specify prior -beta/r ~ N(0,10^6). Since r has prior Exp(0.001),\n# the expected value of r is 1000, and so if we fix this,\n# we can use prior beta ~ N(0, 1000).)\n\n# Prior for shape parameter of the Weibull survival model\nprior.exp <- 0.01 # Gamma(1, 0.001) ~ Exp(0.001) (INLA sets prior on theta, r~Exp(0.1*theta))\nexp.init <- 1.4\n\n\n\nME model ignoring missing observations\nFirst we fit a model to account for the measurement error, using only the complete cases for SBP1.\n\nn <- nrow(ccdata)\n\n# Specifying Y object\nsurv.time <- c(ccdata$t, rep(NA, 3*n))\nevent <- c(ccdata$d, rep(NA, 3*n))\nY.surv <- inla.surv(surv.time/10, event)\nY.expos.sbp <- c(rep(NA, n), rep(0, n), rep(NA, 2*n))\nY.err.sbp <- c(rep(NA, 2*n), ccdata$sbp1, ccdata$sbp2) # Use all available data\nY <- list(Y.surv, Y.expos.sbp, Y.err.sbp)\n\nbeta.0 <- c(rep(1, n), rep(NA, 3*n))\nbeta.sbp <- c(1:n, rep(NA, 3*n))\nbeta.sex <- c(ccdata$sex, rep(NA, 3*n))\nbeta.age <- c(ccdata$age, rep(NA, 3*n))\nbeta.smoke <- c(ccdata$smoke, rep(NA, 3*n))\nbeta.diabetes <- c(ccdata$diabetes, rep(NA, 3*n))\n\n# Insert NAs in last model where w is NA\ntt <- 1:n\ntt[is.na(ccdata$sbp2)] <- NA\nbeta.sbp.copy <- c(rep(NA, n), 1:n, 1:n, tt)\nweight.sbp <- c(rep(NA, n), rep(-1, n), rep(1, 2*n))\n\nalpha.0 <- c(rep(NA, n), rep(1, n), rep(NA, 2*n))\nalpha.sex <- c(rep(NA, n), ccdata$sex, rep(NA, 2*n))\nalpha.age <- c(rep(NA, n), ccdata$age, rep(NA, 2*n))\nalpha.smoke <- c(rep(NA, n), ccdata$smoke, rep(NA, 2*n))\nalpha.diabetes <- c(rep(NA, n), ccdata$diabetes, rep(NA, 2*n))\n\nScale <- c(rep(1, 4*n) )\n\nmat1 <- list(Y = Y,\n           beta.0 = beta.0,\n           beta.sbp = beta.sbp,\n           beta.sex = beta.sex,\n           beta.age = beta.age,\n           beta.smoke = beta.smoke,\n           beta.diabetes = beta.diabetes,\n           beta.sbp.copy = beta.sbp.copy,\n           weight.sbp = weight.sbp,\n           alpha.0 = alpha.0,\n           alpha.sex = alpha.sex,\n           alpha.age = alpha.age,\n           alpha.smoke = alpha.smoke,\n           alpha.diabetes = alpha.diabetes,\n           Scale = Scale)\n\nThe formula is set up as described in Simulation example (except that there we also had a term for the Berkson ME, which we don’t have here).\n\n# INLA formula with copy option\nformula1 <- Y ~ beta.0 - 1 +\n  f(beta.sbp.copy, weight.sbp, model=\"iid\", values = 1:n,\n    hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  f(beta.sbp, copy=\"beta.sbp.copy\",\n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  beta.sex + beta.age + beta.smoke + beta.diabetes +\n  alpha.0 + alpha.sex + alpha.age + alpha.smoke + alpha.diabetes\n\nThe model is then fit.\n\nmodel1 <- inla(formula1, data = mat1,\n                 family = c(\"weibull.surv\", \"gaussian\", \"gaussian\"),\n                 control.family = list(\n                   list(hyper = list(alpha = list(param = prior.exp,\n                                                  initial = log(exp.init),\n                                                  fixed = FALSE))),\n                   list(hyper = list(prec = list(initial = log(prec.x),\n                                                 param = prior.prec.x,\n                                                 fixed = FALSE))),\n                   list(hyper = list(prec = list(initial = log(prec.u),\n                                                 param = prior.prec.u,\n                                                 fixed = FALSE)))\n                 ),\n                 control.predictor=list(link=3),\n                 scale = Scale,\n                 control.fixed = list(\n                   mean = list(beta.0 = prior.beta[1],\n                               beta.sex = prior.beta[1],\n                               beta.age = prior.beta[1],\n                               beta.smoke = prior.beta[1],\n                               beta.diabetes = prior.beta[1],\n                               alpha.0 = prior.alpha[1],\n                               alpha.sex = prior.alpha[1],\n                               alpha.age = prior.alpha[1],\n                               alpha.smoke = prior.alpha[1],\n                               alpha.diabetes = prior.alpha[1]),\n                   prec = list(beta.0 = prior.beta[2],\n                               beta.sex = prior.beta[2],\n                               beta.age = prior.beta[2],\n                               beta.smoke = prior.beta[2],\n                               beta.diabetes = prior.beta[2],\n                               alpha.0 = prior.alpha[2],\n                               alpha.sex = prior.alpha[2],\n                               alpha.age = prior.alpha[2],\n                               alpha.smoke = prior.alpha[2],\n                               alpha.diabetes = prior.alpha[2])))\n\nview_relevant(model1, \"Repeated measurement\")\n\nRepeated measurement \n\n\n                   mean 0.025quant 0.975quant\nbeta.sbp      0.1121153 0.01386680  0.2082771\nbeta.age      0.8716486 0.75627658  0.9866010\nbeta.diabetes 0.5019704 0.27834125  0.7167173\nbeta.sex      0.4903540 0.30615108  0.6789968\nbeta.smoke    0.2631645 0.06519664  0.4564406\n\n\n\n\nME model with missingness in SBP1 and SBP2\nOur full measurement error model account for both the measurement error in the blood pressure measurement, as well as the missingness.\nWe begin by setting up the matrices that define the model structure. Note that we transform the survival time to avoid numerical issues.\n\nn <- nrow(data)\n\n# Specifying Y object\nsurv.time <- c(data$t, rep(NA, 3*n))\nevent <- c(data$d, rep(NA, 3*n))\nY.surv <- inla.surv(surv.time/10, event)\nY.expos.sbp <- c(rep(NA, n), rep(0, n), rep(NA, 2*n))\nY.err.sbp <- c(rep(NA, 2*n), data$sbp1, data$sbp2) # Use all available data\nY <- list(Y.surv, Y.expos.sbp, Y.err.sbp)\n\nbeta.0 <- c(rep(1, n), rep(NA, 3*n))\nbeta.sbp <- c(1:n, rep(NA, 3*n))\nbeta.sex <- c(data$sex, rep(NA, 3*n))\nbeta.age <- c(data$age, rep(NA, 3*n))\nbeta.smoke <- c(data$smoke, rep(NA, 3*n))\nbeta.diabetes <- c(data$diabetes, rep(NA, 3*n))\n\n# Insert NAs in last model where w is NA\ntt <- 1:n\ntt[is.na(data$sbp2)] <- NA\nbeta.sbp.copy <- c(rep(NA, n), 1:n, 1:n, tt)\nweight.sbp <- c(rep(NA, n), rep(-1, n), rep(1, 2*n))\n\nalpha.0 <- c(rep(NA, n), rep(1, n), rep(NA, 2*n))\nalpha.sex <- c(rep(NA, n), data$sex, rep(NA, 2*n))\nalpha.age <- c(rep(NA, n), data$age, rep(NA, 2*n))\nalpha.smoke <- c(rep(NA, n), data$smoke, rep(NA, 2*n))\nalpha.diabetes <- c(rep(NA, n), data$diabetes, rep(NA, 2*n))\n\nScale <- c(rep(1, 4*n) )\n\nmat2 <- list(Y = Y,\n           beta.0 = beta.0,\n           beta.sbp = beta.sbp,\n           beta.sex = beta.sex,\n           beta.age = beta.age,\n           beta.smoke = beta.smoke,\n           beta.diabetes = beta.diabetes,\n           beta.sbp.copy = beta.sbp.copy,\n           weight.sbp = weight.sbp,\n           alpha.0 = alpha.0,\n           alpha.sex = alpha.sex,\n           alpha.age = alpha.age,\n           alpha.smoke = alpha.smoke,\n           alpha.diabetes = alpha.diabetes,\n           Scale = Scale)\n\nThe formula is the same as above.\n\n# INLA formula with copy option\nformula2 <- Y ~ beta.0 - 1 +\n  f(beta.sbp.copy, weight.sbp, model=\"iid\", values = 1:n,\n    hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  f(beta.sbp, copy=\"beta.sbp.copy\",\n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  beta.sex + beta.age + beta.smoke + beta.diabetes +\n  alpha.0 + alpha.sex + alpha.age + alpha.smoke + alpha.diabetes\n\nThe model is then fit.\n\nmodel_bloodpressure <- inla(formula2, data = mat2,\n                 family = c(\"weibull.surv\", \"gaussian\", \"gaussian\"),\n                 control.family = list(\n                   list(hyper = list(alpha = list(param = prior.exp,\n                                                  initial = log(exp.init),\n                                                  fixed = FALSE))),\n                   list(hyper = list(prec = list(initial = log(prec.x),\n                                                 param = prior.prec.x,\n                                                 fixed = FALSE))),\n                   list(hyper = list(prec = list(initial = log(prec.u),\n                                                 param = prior.prec.u,\n                                                 fixed = FALSE)))\n                 ),\n                 control.predictor=list(link=3),\n                 scale = Scale,\n                 control.fixed = list(\n                   mean = list(beta.0 = prior.beta[1],\n                               beta.sex = prior.beta[1],\n                               beta.age = prior.beta[1],\n                               beta.smoke = prior.beta[1],\n                               beta.diabetes = prior.beta[1],\n                               alpha.0 = prior.alpha[1],\n                               alpha.sex = prior.alpha[1],\n                               alpha.age = prior.alpha[1],\n                               alpha.smoke = prior.alpha[1],\n                               alpha.diabetes = prior.alpha[1]),\n                   prec = list(beta.0 = prior.beta[2],\n                               beta.sex = prior.beta[2],\n                               beta.age = prior.beta[2],\n                               beta.smoke = prior.beta[2],\n                               beta.diabetes = prior.beta[2],\n                               alpha.0 = prior.alpha[2],\n                               alpha.sex = prior.alpha[2],\n                               alpha.age = prior.alpha[2],\n                               alpha.smoke = prior.alpha[2],\n                               alpha.diabetes = prior.alpha[2])))\n\nview_relevant(model_bloodpressure, \"Repeated measurement\")\n\nRepeated measurement \n\n\n                   mean 0.025quant 0.975quant\nbeta.sbp      0.1143296 0.01809562  0.2098860\nbeta.age      0.9062324 0.80813899  1.0039959\nbeta.diabetes 0.5949565 0.40939702  0.7746122\nbeta.sex      0.4443801 0.29083679  0.6006210\nbeta.smoke    0.2717879 0.10401999  0.4363125"
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#looking-at-all-the-models",
    "href": "missing_and_mismeasured_covariate.html#looking-at-all-the-models",
    "title": "Missing and mismeasured covariate",
    "section": "Looking at all the models",
    "text": "Looking at all the models\n\n\nNaive model\n\n\n                  mean  0.025quant 0.975quant\n(Intercept) -2.3611508 -2.55027441 -2.1786506\nsbp1         0.0852421  0.01318898  0.1560199\nsex          0.4872863  0.30313969  0.6759058\nage          0.8762591  0.76273395  0.9894474\nsmoke        0.2621554  0.06417933  0.4554144\ndiabetes     0.5032389  0.27969458  0.7178608\n\n\nAdjusts for ME, but only complete cases for SBP1 \n\n\n                   mean 0.025quant 0.975quant\nbeta.sbp      0.1121153 0.01386680  0.2082771\nbeta.age      0.8716486 0.75627658  0.9866010\nbeta.diabetes 0.5019704 0.27834125  0.7167173\nbeta.sex      0.4903540 0.30615108  0.6789968\nbeta.smoke    0.2631645 0.06519664  0.4564406\n\n\nMissingness in both SBP measurements (only complete cases of smoking) \n\n\n                   mean 0.025quant 0.975quant\nbeta.sbp      0.1143296 0.01809562  0.2098860\nbeta.age      0.9062324 0.80813899  1.0039959\nbeta.diabetes 0.5949565 0.40939702  0.7746122\nbeta.sex      0.4443801 0.29083679  0.6006210\nbeta.smoke    0.2717879 0.10401999  0.4363125\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we compare this to the results from Keogh and Bartlett (2021) (see Figure 2 in their paper), our “Complete case naive” corresponds to their “Naive”, and our “ME adjusted complete case” corresponds to their “Bayes^c”. Our “ME adjusted and imputation does not quite correspond to their”Bayes^d”, since they also include an imputation model for smoking in their final model, which we do not. The results for the two models that are comparable are almost identical."
  },
  {
    "objectID": "missing_and_mismeasured_covariate.html#references",
    "href": "missing_and_mismeasured_covariate.html#references",
    "title": "Missing and mismeasured covariate",
    "section": "References",
    "text": "References\nBartlett, J. W. and Keogh, R. H. (2018). Bayesian correction for covariate measurement error: A frequentist evaluation and comparison with regression calibration. Statistical Methods in Medical Research, 27(6):1695–1708.\nKeogh, R. H. and Bartlett, J. W. (2021). Measurement error as a missing data problem. In Handbook of Measurement Error Models, Chapman & Hall/CRC Handbooks of Modern Statistical Methods, pages 429–452. CRC Press. Available as preprint, arXiv:1910.06443."
  },
  {
    "objectID": "data_bloodpressure.html",
    "href": "data_bloodpressure.html",
    "title": "Bloodpressure data",
    "section": "",
    "text": "Repeated systolic blood pressure measurements with measurement error.\nA dataset containing a repeated blood pressure measurement along with some other variables for participants in the Third National Health and Nutrition Survey (NHANES III), merged with data from the US National Death Index by Ruth H. Keogh and Jonathan Bartlett."
  },
  {
    "objectID": "data_bloodpressure.html#load-the-data",
    "href": "data_bloodpressure.html#load-the-data",
    "title": "Bloodpressure data",
    "section": "Load the data",
    "text": "Load the data\nIf you have cloned the repository:\n\nbloodpressure <- read.csv(\"data/bloodpressure.csv\")\n\nOtherwise you can download it from GitHub like this:\n\nlibrary(RCurl)\n\nurl_bloodpressure <- getURL(\"https://raw.githubusercontent.com/emmaSkarstein/Missing-data-and-measurement-error/master/data/bloodpressure.csv\")\nbloodpressure <- read.csv(text = url_bloodpressure)"
  },
  {
    "objectID": "data_bloodpressure.html#format",
    "href": "data_bloodpressure.html#format",
    "title": "Bloodpressure data",
    "section": "Format",
    "text": "Format\nA data frame with 6519 rows and 8 variables:\n\nsbp1: systolic blood pressure (standardized), first measurement\nsbp2: systolic blood pressure (standardized), second measurement\nsex: Sex (0 = female, 1 = male)\nage: Age (standardized)\nsmoke: Smoking status (0 = no, 1 = yes)\ndiabetes: diabetes status (0 = no, 1 = yes)\nd: censoring status (0 = censored, 1 = observed death due to cardiovascular disease)\nt: time until death due to cardiovascular disease occurs"
  },
  {
    "objectID": "data_bloodpressure.html#source",
    "href": "data_bloodpressure.html#source",
    "title": "Bloodpressure data",
    "section": "Source",
    "text": "Source\nhttps://github.com/ruthkeogh/meas_error_handbook"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplementary material and reproducible research files for article “A joint Bayesian framework for missing data and measurement error using integrated nested Laplace approximations”",
    "section": "",
    "text": "Preprint: arxiv.org/abs/2303.15240\nAuthors: Skarstein, E., Martino, S., Muff, S.\nThis supplementary material was written by Skarstein, E., but code for analysis was developed jointly between authors.\nIn case of any questions or comments, please do not hesitate to contact emma.s.skarstein@ntnu.no!\nThis website contains scripts, tutorials and data to reproduce all analysis and figures from the manuscript."
  },
  {
    "objectID": "index.html#examples",
    "href": "index.html#examples",
    "title": "Supplementary material and reproducible research files for article “A joint Bayesian framework for missing data and measurement error using integrated nested Laplace approximations”",
    "section": "Examples",
    "text": "Examples\nThese include scripts to run the code for analysis, including comments and explanations.\nFor a step-by-step introduction with detailed explanations, see Simulation example. This is a single sun of the simulation study shown in the paper, and the full code for the study can be found in Simulation study. The data and model used in these examples reflect the most general case where we have a covariate with classical and Berkson measurement error, as well as missing data. For many users inlabru might be more intuitive than plain INLA, and so we have also included the same model implemented in inlabru in Example in inlabru.\nThe remaining examples are variations on the above model using different data sets, see the table below for an overview of the different types of ME in the different examples.\n\n\n\nExample\nClassical ME\nBerkson ME\nMissing data\n\n\n\n\nMissing covariate imputation\n\n\nx\n\n\nMissing and mismeasured covariate\nx\n\nx\n\n\nSimulation study\nx\nx\nx\n\n\nSimulation example\nx\nx\nx\n\n\nExample in inlabru\nx\nx\nx"
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "Supplementary material and reproducible research files for article “A joint Bayesian framework for missing data and measurement error using integrated nested Laplace approximations”",
    "section": "Datasets",
    "text": "Datasets\nAll the data sets that are used in the paper can be downloaded manually from the GitHub repository, or directly in R as specified in the data descriptions."
  },
  {
    "objectID": "index.html#session-info",
    "href": "index.html#session-info",
    "title": "Supplementary material and reproducible research files for article “A joint Bayesian framework for missing data and measurement error using integrated nested Laplace approximations”",
    "section": "Session info",
    "text": "Session info\nThe code was written and run in R with the following software versions:\n\n\n\ninla.version()\nR-INLA version ..........: 22.05.07\nDate ....................: Sat May 7 12:43:31 PM +03 2022 (Version_22.05.07)\nMaintainers .............: Havard Rue <hrue@r-inla.org>\n                         : Finn Lindgren <finn.lindgren@gmail.com>\n                         : Elias Teixeira Krainski <elias@r-inla.org>\nMain web-page ...........: www.r-inla.org\nDownload-page ...........: inla.r-inla-download.org\nRepository ..............: github.com/hrue/r-inla\nEmail support ...........: help@r-inla.org\n                         : r-inla-discussion-group@googlegroups.com\n\n\n\n Current session info \n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.1 (2022-06-23)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Oslo\n date     2023-06-23\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version  date (UTC) lib source\n class          7.3-20   2022-01-16 [1] CRAN (R 4.2.1)\n classInt       0.4-8    2022-09-29 [1] CRAN (R 4.2.0)\n cli            3.6.1    2023-03-23 [1] CRAN (R 4.2.0)\n codetools      0.2-18   2020-11-04 [1] CRAN (R 4.2.1)\n colorspace     2.1-0    2023-01-23 [1] CRAN (R 4.2.0)\n DBI            1.1.3    2022-06-18 [1] CRAN (R 4.2.0)\n e1071          1.7-12   2022-10-24 [1] CRAN (R 4.2.0)\n fansi          1.0.4    2023-01-22 [1] CRAN (R 4.2.0)\n farver         2.1.1    2022-07-06 [1] CRAN (R 4.2.0)\n foreach      * 1.5.2    2022-02-02 [1] CRAN (R 4.2.0)\n ggplot2        3.4.2    2023-04-03 [1] CRAN (R 4.2.0)\n glue           1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n gtable         0.3.3    2023-03-21 [1] CRAN (R 4.2.0)\n INLA         * 22.05.07 2022-05-07 [1] local\n inlabru        2.7.0    2022-12-02 [1] CRAN (R 4.2.0)\n isoband        0.2.7    2022-12-20 [1] CRAN (R 4.2.0)\n iterators      1.0.14   2022-02-05 [1] CRAN (R 4.2.0)\n KernSmooth     2.23-20  2021-05-03 [1] CRAN (R 4.2.1)\n labeling       0.4.2    2020-10-20 [1] CRAN (R 4.2.0)\n lattice        0.20-45  2021-09-22 [1] CRAN (R 4.2.1)\n lifecycle      1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n magrittr       2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n MASS           7.3-57   2022-04-22 [1] CRAN (R 4.2.1)\n Matrix       * 1.5-1    2022-09-13 [1] CRAN (R 4.2.0)\n MatrixModels   0.5-1    2022-09-11 [1] CRAN (R 4.2.0)\n mgcv           1.8-40   2022-03-29 [1] CRAN (R 4.2.1)\n munsell        0.5.0    2018-06-12 [1] CRAN (R 4.2.0)\n nlme           3.1-157  2022-03-25 [1] CRAN (R 4.2.1)\n patchwork      1.1.2    2022-08-19 [1] CRAN (R 4.2.0)\n pillar         1.9.0    2023-03-22 [1] CRAN (R 4.2.0)\n pkgconfig      2.0.3    2019-09-22 [1] CRAN (R 4.2.0)\n plyr           1.8.7    2022-03-24 [1] CRAN (R 4.2.0)\n proxy          0.4-27   2022-06-09 [1] CRAN (R 4.2.0)\n R6             2.5.1    2021-08-19 [1] CRAN (R 4.2.0)\n RColorBrewer   1.1-3    2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp           1.0.10   2023-01-22 [1] CRAN (R 4.2.0)\n rgdal          1.5-32   2022-05-09 [1] CRAN (R 4.2.0)\n rlang          1.1.1    2023-04-28 [1] CRAN (R 4.2.0)\n s2             1.1.0    2022-07-18 [1] CRAN (R 4.2.0)\n scales         1.2.1    2022-08-20 [1] CRAN (R 4.2.0)\n sf             1.0-12   2023-03-19 [1] CRAN (R 4.2.0)\n sp           * 1.6-0    2023-01-19 [1] CRAN (R 4.2.0)\n tibble         3.2.1    2023-03-20 [1] CRAN (R 4.2.0)\n units          0.8-0    2022-02-05 [1] CRAN (R 4.2.0)\n utf8           1.2.3    2023-01-31 [1] CRAN (R 4.2.0)\n vctrs          0.6.2    2023-04-19 [1] CRAN (R 4.2.0)\n viridisLite    0.4.1    2022-08-22 [1] CRAN (R 4.2.0)\n withr          2.5.0    2022-03-03 [1] CRAN (R 4.2.0)\n wk             0.7.0    2022-10-13 [1] CRAN (R 4.2.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "data_nhanes.html",
    "href": "data_nhanes.html",
    "title": "NHANES example",
    "section": "",
    "text": "A small data set with missing values."
  },
  {
    "objectID": "data_nhanes.html#load-the-data",
    "href": "data_nhanes.html#load-the-data",
    "title": "NHANES example",
    "section": "Load the data",
    "text": "Load the data\n\nlibrary(mice)\ndata(nhanes2)"
  },
  {
    "objectID": "data_nhanes.html#format",
    "href": "data_nhanes.html#format",
    "title": "NHANES example",
    "section": "Format",
    "text": "Format\nA data frame with 25 rows and 4 variables:\n\nage: Age group (1=20-39, 2=40-59, 3=60+)\nbmi: Age group (1=20-39, 2=40-59, 3=60+)\nhyp: Hypertensive (1=no,2=yes)\nchl: Total serum cholesterol (mg/dL)"
  },
  {
    "objectID": "data_nhanes.html#source",
    "href": "data_nhanes.html#source",
    "title": "NHANES example",
    "section": "Source",
    "text": "Source\nThe {mice} package, originally from Schafer, J.L. (1997). Analysis of Incomplete Multivariate Data. London: Chapman & Hall. Table 6.14."
  },
  {
    "objectID": "data_simulated.html",
    "href": "data_simulated.html",
    "title": "Simulated data",
    "section": "",
    "text": "A dataset containing three simulated variables, generated in the example “Simulation: Berkson and classical measurement error alongside missing data”.\n\nLoad the data\nIf you have cloned the repository:\n\nsimulated_data <- read.csv(\"data/simulated_data.csv\")\n\nOtherwise you can download the data from GitHub like this:\n\nlibrary(RCurl)\n\nurl_simulated_data <- getURL(\"https://raw.githubusercontent.com/emmaSkarstein/Missing-data-and-measurement-error/master/data/simulated_data.csv\")\nsimulated_data <- read.csv(text = url_simulated_data)\n\n\n\nFormat\nA data frame with 1000 rows and 3 variables:\n\ny: response variable, continuous\nw: covariate with classical and Berkson measurement error, and missing data, continuous\nz: covariate with no error or missingness, continuous"
  },
  {
    "objectID": "example_in_inlabru.html",
    "href": "example_in_inlabru.html",
    "title": "Example in inlabru",
    "section": "",
    "text": "library(INLA)\nlibrary(inlabru)\nWe here show how to fit the measurement error and missing data model in inlabru. The inlabru code is written by Sara Martino, and commented by Emma Skarstein."
  },
  {
    "objectID": "example_in_inlabru.html#loading-the-data",
    "href": "example_in_inlabru.html#loading-the-data",
    "title": "Example in inlabru",
    "section": "Loading the data",
    "text": "Loading the data\nFor this demonstration we will use the simulated data from the Simulation example. Just to refresh: this is a situation where we have one covariate (\\(\\boldsymbol{x}\\)) that has both classical error, Berkson error and missing data. We also observe another covariate (\\(\\boldsymbol{z}\\)) that has no error.\n\ndata <- read.csv(\"data/simulated_data.csv\")\nn <- nrow(data)"
  },
  {
    "objectID": "example_in_inlabru.html#priors",
    "href": "example_in_inlabru.html#priors",
    "title": "Example in inlabru",
    "section": "Priors",
    "text": "Priors\nWe use the exact same priors as in the original simulation study.\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 1/1000) # N(0, 10^3)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1/10000) # N(0, 10^4) \n\n# Priors for y, measurement error and true x-value precision\nprior.prec.y <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_b <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.u_c <- c(0.5, 0.5) # Gamma(0.5, 0.5)\nprior.prec.r <- c(0.5, 0.5) # Gamma(0.5, 0.5) \nprior.prec.x <- c(0.5, 0.5)\n\n\n# Initial values\nprec.y <- 1\nprec.u_b <- 1\nprec.u_c <- 1\nprec.r <- 1\nprec.x <- 1"
  },
  {
    "objectID": "example_in_inlabru.html#specifying-the-data",
    "href": "example_in_inlabru.html#specifying-the-data",
    "title": "Example in inlabru",
    "section": "Specifying the data",
    "text": "Specifying the data\n\n# Regression model of interest \ndata_moi <- data.frame(y = data$y, z = data$z, weight.x = 1, weight.r = 1, r = 1:n) \n\n# Berkson ME model\ndata_berkson <- data.frame(zero = 0, weight.x = -1, weight.r = 1, r = 1:n) \n\n# Classical ME model\ndata_classical <- data.frame(w = data$w, weight.x = 1, weight.r = 1, r = 1:n)\n\n# Imputation model\ndata_imputation <- data.frame(zero = 0, z = data$z, weight.x = 1, weight.r = -1, r = 1:n)"
  },
  {
    "objectID": "example_in_inlabru.html#formulas",
    "href": "example_in_inlabru.html#formulas",
    "title": "Example in inlabru",
    "section": "Formulas",
    "text": "Formulas\n\ncmp_new <- ~ Intercept(1, model = \"linear\", prec.linear = prior.beta[2]) +\n  beta_z(main = z, model = \"linear\", prec.linear = prior.beta[2]) +\n  x_eff(r, weight.x, model = \"iid\",  hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  x_eff_copy(r, copy=\"x_eff\", hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  r_eff(r, weight.r, model = \"iid\",  hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  alpha_0(main = 1, model = \"linear\", prec.linear = prior.alpha[2]) +\n  alpha_z(main = z, model = \"linear\", prec.linear = prior.alpha[2])\n\n\nlik_moi <- like(formula = y ~ .,\n                family = \"gaussian\",\n                include = c(\"Intercept\", \"beta_z\", \"x_eff_copy\"),\n                control.family = list(\n                  hyper = list(prec = list(initial = log(prec.y), \n                                           param = prior.prec.y, \n                                           fixed = FALSE))),\n            data = data_moi)\n\nlik_berkson <- like(formula = zero ~ .,\n                    family = \"gaussian\",\n                    include = c(\"x_eff\", \"r_eff\"),\n                    control.family = list(\n                      hyper = list(prec = list(initial = log(prec.u_b),\n                                               param = prior.prec.u_b,\n                                               fixed = FALSE))),\n                    data = data_berkson)\n\nlik_classical <- like(formula = w ~ .,\n                      family = \"gaussian\",\n                      include = c(\"r_eff\"),\n                      control.family =  list(\n                        hyper = list(prec = list(initial = log(prec.u_c), \n                                                 param = prior.prec.u_c, \n                                                 fixed = FALSE))),\n            data  = data_classical)\n\nlik_imputation <- like(formula = zero ~ .,\n                       family = \"gaussian\",\n                       include = c(\"alpha_0\", \"alpha_z\",\"r_eff\"),\n                       control.family =   list(\n                         hyper = list(prec = list(initial = log(prec.r), \n                                                  param = prior.prec.r, \n                                                  fixed = FALSE))),\n             data = data_imputation)"
  },
  {
    "objectID": "example_in_inlabru.html#fitting-the-model",
    "href": "example_in_inlabru.html#fitting-the-model",
    "title": "Example in inlabru",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nbru_options_set(bru_verbose = 1)\nfit <- bru(components = cmp_new,\n           lik_moi,\n           lik_berkson,\n           lik_classical,\n           lik_imputation,\n           options = list(verbose = F,\n                          bru_max_iter = 20,\n                          inla.mode  = \"experimental\"))\nfit$summary.fixed\n\n              mean         sd 0.025quant 0.5quant 0.975quant mode          kld\nIntercept 1.000871 0.17477625  0.6171142 1.023330   1.291305   NA 1.219935e-06\nbeta_z    2.070481 0.30233865  1.4000095 2.132443   2.520561   NA 8.593488e-06\nalpha_0   1.005297 0.04730354  0.9125180 1.005296   1.098081   NA 1.257765e-11\nalpha_z   1.987651 0.04889942  1.8917480 1.987648   2.083571   NA 1.323263e-11\n\nfit$summary.hyperpar\n\n                                                mean         sd 0.025quant\nPrecision for the Gaussian observations    1.3215370 0.12891126  1.1204920\nPrecision for the Gaussian observations[2] 0.9835689 0.11150074  0.7666513\nPrecision for the Gaussian observations[3] 1.1465015 0.07147174  0.9476022\nPrecision for the Gaussian observations[4] 0.9761411 0.04944324  0.9398728\nBeta for x_eff_copy                        1.9862676 0.09205144  1.9235916\n                                           0.5quant 0.975quant mode\nPrecision for the Gaussian observations    1.511967   1.896480   NA\nPrecision for the Gaussian observations[2] 1.260254   1.480340   NA\nPrecision for the Gaussian observations[3] 1.049763   1.197601   NA\nPrecision for the Gaussian observations[4] 1.042509   1.129890   NA\nBeta for x_eff_copy                        2.113436   2.261097   NA"
  },
  {
    "objectID": "missing_covariate_imputation.html",
    "href": "missing_covariate_imputation.html",
    "title": "Missing covariate imputation",
    "section": "",
    "text": "In this example, we use the nhanes2 data set from the mice R-package to illustrate how to do missing covariate imputation in INLA by using a measurement error model. As noted in the paper, the nhanes2 data set is really small, it only has 25 observations and 9 of them are missing, so this is not really a good application of this. However, we chose to use this as it is a data set that is commonly used in other missing data applications in INLA, and so we reasoned that using the same data set would make it easier to compare the implementations."
  },
  {
    "objectID": "missing_covariate_imputation.html#loading-packages",
    "href": "missing_covariate_imputation.html#loading-packages",
    "title": "Missing covariate imputation",
    "section": "Loading packages",
    "text": "Loading packages\n\nlibrary(mice)       # Just used for the nhanes2 data set\nlibrary(INLA)       # INLA modelling\nlibrary(dplyr)      # Data wrangling of the results\nlibrary(gt)         # Tables\nlibrary(tidyverse)  # Data wrangling and plotting\nlibrary(showtext)   # Font\nlibrary(colorspace) # Color adjustments\n\n\ninla.setOption(num.threads = \"1:1\")"
  },
  {
    "objectID": "missing_covariate_imputation.html#loading-and-preparing-the-data",
    "href": "missing_covariate_imputation.html#loading-and-preparing-the-data",
    "title": "Missing covariate imputation",
    "section": "Loading and preparing the data",
    "text": "Loading and preparing the data\n\n# Using the nhanes data set found in mice:\ndata(nhanes2)\n\nnhanes2\n\n     age  bmi  hyp chl\n1  20-39   NA <NA>  NA\n2  40-59 22.7   no 187\n3  20-39   NA   no 187\n4  60-99   NA <NA>  NA\n5  20-39 20.4   no 113\n6  60-99   NA <NA> 184\n7  20-39 22.5   no 118\n8  20-39 30.1   no 187\n9  40-59 22.0   no 238\n10 40-59   NA <NA>  NA\n11 20-39   NA <NA>  NA\n12 40-59   NA <NA>  NA\n13 60-99 21.7   no 206\n14 40-59 28.7  yes 204\n15 20-39 29.6   no  NA\n16 20-39   NA <NA>  NA\n17 60-99 27.2  yes 284\n18 40-59 26.3  yes 199\n19 20-39 35.3   no 218\n20 60-99 25.5  yes  NA\n21 20-39   NA <NA>  NA\n22 20-39 33.2   no 229\n23 20-39 27.5   no 131\n24 60-99 24.9   no  NA\n25 40-59 27.4   no 186\n\nn <- nrow(nhanes2)\n\n# Manually dummy-code age:\nage2 <- ifelse(nhanes2$age == \"40-59\", 1, 0)\nage3 <- ifelse(nhanes2$age == \"60-99\", 1, 0)\n\n# Center the response and continuous covariates\nchl <- scale(nhanes2$chl, scale = FALSE)[,1]\nbmi <- scale(nhanes2$bmi, scale = FALSE)[,1]"
  },
  {
    "objectID": "missing_covariate_imputation.html#aim",
    "href": "missing_covariate_imputation.html#aim",
    "title": "Missing covariate imputation",
    "section": "Aim",
    "text": "Aim\nWe want to fit the model\n\\[\nchl \\sim \\beta_0 + \\beta_{age2} age_2 + \\beta_{age3} age_3 + \\beta_{bmi} bmi + \\varepsilon,\n\\] but there is missingness in bmi, so we will consider two different imputation models for this."
  },
  {
    "objectID": "missing_covariate_imputation.html#simple-imputation-model",
    "href": "missing_covariate_imputation.html#simple-imputation-model",
    "title": "Missing covariate imputation",
    "section": "Simple imputation model",
    "text": "Simple imputation model\nWe first fit a model that is identical to the one in Gómez-Rubio and Rue (2018).\n\nSpecifying priors\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 0.001) # Gaussian, c(mean, precision)\n\n# Priors for exposure model coefficient\n#prior.alpha <- c(26.56, 1/71.07) # Gaussian, c(mean, precision)\n\n# Priors for y, measurement error\nprior.prec.y <- c(1, 0.00005) # Gamma\nprior.prec.u_c <- c(0.5, 0.5) # Gamma\n#prior.prec.x <- c(2.5-1,(2.5)*4.2^2) # Gamma\n\n# Initial values\nprec.y <- 1\nprec.u_c <- 1\n#prec.x <- 1/71.07\nprec.x <- 1/71.07\n\n\n\nSetting up the matrices for the joint model\n\nY <- matrix(NA, 3*n, 3)\n\nY[1:n, 1] <- chl             # Regression model of interest response\nY[n+(1:n), 2] <- bmi         # Error model response\nY[2*n+(1:n), 3] <- rep(0, n) # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, n), rep(NA, n))\nbeta.bmi <- c(1:n, rep(NA, n), rep(NA, n))\nbeta.age2 <- c(age2, rep(NA, n), rep(NA, n))\nbeta.age3 <- c(age3, rep(NA, n), rep(NA, n))\n\nid.x <- c(rep(NA, n), 1:n, 1:n) \nweight.x <- c(rep(1, n), rep(1, n), rep(-1, n))\n\noffset.imp <- c(rep(NA, n), rep(NA, n), rep(26.56, n))\n\ndd <- data.frame(Y = Y, \n                 beta.0 = beta.0,\n                 beta.bmi = beta.bmi,\n                 beta.age2 = beta.age2,\n                 beta.age3 = beta.age3,\n                 id.x = id.x,\n                 weight.x = weight.x,\n                 offset.imp = offset.imp)\n\n\n\nINLA formula\n\nformula = Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + \n  f(beta.bmi, copy=\"id.x\", \n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  f(id.x, weight.x, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed=TRUE)))\n\n\n\nScaling of ME precision\nSince we are not assuming any measurement error here, we need to “turn off” the error model by scaling the error precision to be very large (it makes no difference if we scale the precision only for the observed values or for the observed and missing values).\n\nScale <- c(rep(1, n), rep(10^12, n), rep(1, n))\n\n\n\nFitting the model\n\nmodel_missing1 <- inla(formula, data = dd, scale = Scale, offset = log(dat$pop),\n                     family = c(\"gaussian\", \"gaussian\", \"gaussian\"),\n                     control.family = list(\n                       list(hyper = list(prec = list(initial = log(prec.y), \n                                                     param = prior.prec.y, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.u_c), \n                                                     param = prior.prec.u_c, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.x),\n                                                     fixed = TRUE)))\n                     ),\n                     control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2])),\n                     verbose=F)\nmodel_missing1$summary.fixed\n\n               mean       sd 0.025quant  0.5quant 0.975quant mode          kld\nbeta.0    -17.60626 10.93451 -37.971728 -18.03594   5.183261   NA 9.910360e-08\nbeta.age2  29.24290 16.09734  -4.203562  29.84339  59.318094   NA 9.648499e-08\nbeta.age3  51.16447 20.73070   7.996870  52.09611  89.369885   NA 1.611619e-07\n\nmodel_missing1$summary.hyperpar\n\n                                                  mean           sd\nPrecision for the Gaussian observations    0.001036804 0.0004234011\nPrecision for the Gaussian observations[2] 0.916159737 0.5484311863\nBeta for beta.bmi                          5.035216083 0.4842624861\n                                             0.025quant     0.5quant\nPrecision for the Gaussian observations    0.0003789667 0.0009755623\nPrecision for the Gaussian observations[2] 0.2023001516 0.8039241305\nBeta for beta.bmi                          4.1750752965 5.0067526677\n                                            0.975quant mode\nPrecision for the Gaussian observations    0.002025766   NA\nPrecision for the Gaussian observations[2] 2.276555004   NA\nBeta for beta.bmi                          6.082937710   NA"
  },
  {
    "objectID": "missing_covariate_imputation.html#full-imputation-model",
    "href": "missing_covariate_imputation.html#full-imputation-model",
    "title": "Missing covariate imputation",
    "section": "Full imputation model",
    "text": "Full imputation model\nThis model includes age as a covariate in the imputation model.\n\nSpecifying priors\nFor the intercepts and slopes of the model of interest and imputation model we set very wide priors centered at zero.\n\n# Priors for model of interest coefficients\nprior.beta = c(0, 1e-6) # Gaussian, c(mean, precision)\n\n# Priors for exposure model coefficients\nprior.alpha <- c(0, 1e-6) # Gaussian, c(mean, precision)\n\nFor the precision of \\(y\\) and \\(x\\) we set more informative priors. The precisions are given gamma priors, and in INLA this is parameterized by the shape and rate parameters. Let’s first look at the precision for \\(y\\).\nWe base our priors for \\(x\\) and \\(y\\) around the values that we want as the modes of the distributions. For \\(y\\), we look at the regression chl~bmi+age2+age3. The standard error is estimated to be \\(29.1\\). We decide we want \\(1/29.1^2\\) to be the mode of our prior. Since the gamma distribution with shape \\(\\alpha\\) and rate \\(\\beta\\) has mode \\(\\frac{\\alpha-1}{\\beta}\\), we can choose \\(\\alpha = s+1\\) and \\(\\beta = s\\cdot29.1^2\\) in order to get a distribution with mode equal to \\(1/29.1^2\\). Then we need to choose \\(s\\) to decide the spread, the variance of the inverse gamma distribution will decrease as \\(s\\) increases. For \\(x\\) we similarly construct the prior to have its mode at \\(4.1\\).\nAn alternative approach could be to construct an upper limit for the variance by choosing that to be the variance of the covariate itself, as well as some lower limit, and then select the inverses of these limits to be the 2.7% and 97.5% quantiles in the gamma prior. in our case, the variance of chl is \\(2044\\), so we would choose \\(1/2044\\) to be the lower limit for \\(\\tau_y\\). For the upper limit, we decide on roughly a 10th of that variation, so the upper limit is \\(1/204.4\\). By specifying these points as the 2.7% and 97.5% quantiles, respectively, we can achieve the parameters of a gamma distribution with these quantiles through numerical optimization. We get the distribution \\(\\tau_y \\sim G(3.4, 1588)\\). Similarly, for \\(x\\) (bmi), we find that the sample variance of bmi is \\(17.8\\), and so we could set the lower limit of \\(\\tau_x\\) to \\(1/17.8\\). Again, by choosing roughly a 10th of that variation we get a upper limit for the precision at \\(1/1.78\\), giving the gamma distribution \\(\\tau_x \\sim G(3.4, 13.9)\\).\n\n# Priors for y, measurement error and true x-value precision\n# Start by getting a reasonable prior guess for the standard error of the regression and exp. models\nsummary(lm(chl~bmi+age2+age3))$sigma\n\n[1] 29.10126\n\nsummary(lm(bmi~age2+age3))$sigma\n\n[1] 4.160342\n\n# Use those values to create reasonable priors:\ns <- 0.5\nprior.prec.y <- c(s+1, s*29.1^2) # Gamma\nprior.prec.x <- c(s+1, s*4.1^2) # Gamma\n\n# We can visualize these priors:\ncurve(dgamma(x, s+1, s*29.1^2), 0, 0.02) \nabline(v=1/(29.1^2))\n\n\n\ncurve(dgamma(x, s+1, s*4.1^2), 0, 1)\nabline(v=1/(4.2^2))\n\n\n\n# Initial values\nprec.y <- 1/29.1^2\nprec.u_c <- 1\nprec.x <- 1/4.2^2\n\n\n\nSetting up the matrices for the joint model\n\nY <- matrix(NA, 3*n, 3)\n\n\nY[1:n, 1] <- chl             # Regression model of interest response\nY[n+(1:n), 2] <- bmi         # Error model response\nY[2*n+(1:n), 3] <- rep(0, n) # Imputation model response\n\nbeta.0 <- c(rep(1, n), rep(NA, n), rep(NA, n))\nbeta.bmi <- c(1:n, rep(NA, n), rep(NA, n))\nbeta.age2 <- c(age2, rep(NA, n), rep(NA, n))\nbeta.age3 <- c(age3, rep(NA, n), rep(NA, n))\n\nid.x <- c(rep(NA, n), 1:n, 1:n) \nweight.x <- c(rep(1, n), rep(1, n), rep(-1, n))\n\nalpha.0 <- c(rep(NA, n), rep(NA, n), rep(1, n))\nalpha.age2 <- c(rep(NA, n), rep(NA, n), age2)\nalpha.age3 <- c(rep(NA, n), rep(NA, n), age3)\n\ndd <- data.frame(Y = Y, \n                 beta.0 = beta.0,\n                 beta.bmi = beta.bmi,\n                 beta.age2 = beta.age2,\n                 beta.age3 = beta.age3,\n                 id.x = id.x,\n                 weight.x = weight.x,\n                 alpha.0 = alpha.0,\n                 alpha.age2 = alpha.age2,\n                 alpha.age3 = alpha.age3)\n\n\n\nINLA formula\n\nformula = Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + \n  f(beta.bmi, copy=\"id.x\", \n    hyper = list(beta = list(param = prior.beta, fixed=FALSE))) +\n  f(id.x, weight.x, model=\"iid\", values = 1:n, \n    hyper = list(prec = list(initial = -15, fixed=TRUE))) +\n  alpha.0 + alpha.age2 + alpha.age3\n\n\n\nScaling of ME precision\nSince we are (again) not assuming any measurement error here, we need to “turn off” the error model by scaling the error precision to be very large (it makes no difference if we scale the precision only for the observed values or for the observed and missing values).\n\nScale <- c(rep(1, n), rep(10^12, n), rep(1, n))\n\n\n\nFitting the model\n\nmodel_missing2 <- inla(formula, data = dd, scale = Scale,\n                     family = c(\"gaussian\", \"gaussian\", \"gaussian\"),\n                     control.family = list(\n                       list(hyper = list(prec = list(initial = log(prec.y), \n                                                     param = prior.prec.y, \n                                                     fixed = FALSE))),\n                       list(hyper = list(prec = list(initial = log(prec.u_c),\n                                                     fixed = TRUE))),\n                       list(hyper = list(prec = list(initial = log(prec.x), \n                                                     param = prior.prec.x, \n                                                     fixed = FALSE)))\n                     ),\n                     control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],  \n                                   alpha.0 = prior.alpha[1], \n                                   alpha.age2 = prior.alpha[1],\n                                   alpha.age3 = prior.alpha[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   alpha.0 = prior.alpha[2], \n                                   alpha.age2 = prior.alpha[2],\n                                   alpha.age3 = prior.alpha[2])),\n                     verbose=F)\n\n\n# Save results:\nsaveRDS(model_missing2, file = \"results/model_missing2.rds\")"
  },
  {
    "objectID": "missing_covariate_imputation.html#fitting-a-complete-case-model",
    "href": "missing_covariate_imputation.html#fitting-a-complete-case-model",
    "title": "Missing covariate imputation",
    "section": "Fitting a complete case model",
    "text": "Fitting a complete case model\n\n# Where is bmi missing? \nmissing_bmi <- is.na(bmi)\n\ndd_naive <- data.frame(Y = chl, \n                       beta.0 = rep(1, length(bmi)),\n                       beta.bmi = bmi, \n                       beta.age2 = age2, \n                       beta.age3 = age3)[!missing_bmi, ]\n\n\n# Formula\nformula <- Y ~ - 1 + beta.0 + beta.age2 + beta.age3 + beta.bmi\n\n# Fit model\nmodel_naive <- inla(formula,\n              data = dd_naive,\n              family = c(\"gaussian\"),\n              control.family = list(\n                list(hyper = list(prec = list(initial = prec.y, \n                                              param = prior.prec.y, \n                                              fixed = FALSE)))),\n              control.fixed = list(\n                       mean = list(beta.0 = prior.beta[1], \n                                   beta.age2 = prior.beta[1], \n                                   beta.age3 = prior.beta[1],\n                                   beta.bmi = prior.beta[1]), \n                       prec = list(beta.0 = prior.beta[2], \n                                   beta.age2 = prior.beta[2], \n                                   beta.age3 = prior.beta[2],  \n                                   beta.bmi = prior.beta[2]))\n)"
  },
  {
    "objectID": "missing_covariate_imputation.html#results",
    "href": "missing_covariate_imputation.html#results",
    "title": "Missing covariate imputation",
    "section": "Results",
    "text": "Results\nThe posterior means and standard deviations are presented in the table below. Note that the data set is quite small (25 observations where 9 are missing), and so the differing result should not be interpreted too seriously.\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      \n      \n        me_adjusted\n      \n      \n        naive\n      \n      \n        inla_mcmc\n      \n    \n    \n      mean\n      lower\n      upper\n      mean\n      lower\n      upper\n      mean\n      lower\n      upper\n    \n  \n  \n    \n      Model of interest\n    \n    beta.0\n-32.246\n-53.825\n-10.209\n-36.471\n-60.971\n-11.955\n43.469\n-79.233\n166.171\n    beta.age2\n49.780\n16.172\n82.716\n55.767\n19.014\n92.496\n29.501\n-5.526\n64.528\n    beta.age3\n83.479\n40.509\n124.367\n104.643\n55.072\n154.173\n49.449\n3.963\n94.935\n    Beta for beta.bmi\n4.935\n3.541\n6.181\n6.919\n3.026\n10.811\n4.864\n0.540\n9.188\n    \n      Imputation model\n    \n    alpha.0\n1.983\n-0.979\n4.978\nNA\nNA\nNA\nNA\nNA\nNA\n    alpha.age2\n-3.126\n-7.829\n1.544\nNA\nNA\nNA\nNA\nNA\nNA\n    alpha.age3\n-4.525\n-9.547\n0.320\nNA\nNA\nNA\nNA\nNA\nNA\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also look at the imputed values themselves, they can be found in marginals.random$id.x inside the model object.\n\nbmi_imputed <- model_missing2$marginals.random$id.x[missing_bmi]\nbmi_imp_df <- data.table::rbindlist(lapply(bmi_imputed, as.data.frame), idcol = TRUE)\n\nggplot(bmi_imp_df, aes(x = x, y = y)) +\n  geom_line() +\n  facet_wrap(~ .id, ncol = 3) +\n  theme_minimal()\n\n\n\n\nA summary can also be seen from summary.random$id.x:\n\nmodel_missing2$summary.random$id.x[,1:6]\n\n   ID       mean           sd  0.025quant   0.5quant 0.975quant\n1   1  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n2   2 -3.8624998 0.0009999933  -3.8644610 -3.8624998 -3.8605387\n3   3  3.2045709 3.3767919876  -3.4545358  3.2001626  9.8975173\n4   4 -2.5416313 4.5282288945 -11.6122240 -2.5139190  6.3676961\n5   5 -6.1624995 0.0009999933  -6.1644607 -6.1624995 -6.1605384\n6   6 -5.7573424 3.8336379811 -13.3935391 -5.7357398  1.7336245\n7   7 -4.0624997 0.0009999933  -4.0644609 -4.0624997 -4.0605386\n8   8  3.5375000 0.0009999933   3.5355388  3.5375000  3.5394611\n9   9 -4.5624993 0.0009999933  -4.5644605 -4.5624993 -4.5605382\n10 10 -1.1424814 4.4628547510 -10.0052047 -1.1424825  7.7202482\n11 11  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n12 12 -1.1424814 4.4628547510 -10.0052047 -1.1424825  7.7202482\n13 13 -4.8624999 0.0009999933  -4.8644611 -4.8624999 -4.8605388\n14 14  2.1374996 0.0009999933   2.1355385  2.1374996  2.1394608\n15 15  3.0374999 0.0009999933   3.0355388  3.0374999  3.0394611\n16 16  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n17 17  0.6375001 0.0009999933   0.6355389  0.6375001  0.6394612\n18 18 -0.2625001 0.0009999933  -0.2644613 -0.2625001 -0.2605390\n19 19  8.7374996 0.0009999933   8.7355385  8.7374996  8.7394608\n20 20 -1.0625001 0.0009999933  -1.0644612 -1.0625001 -1.0605390\n21 21  1.9833916 4.3417083305  -6.6211007  1.9775924 10.6216277\n22 22  6.6374999 0.0009999933   6.6355388  6.6374999  6.6394611\n23 23  0.9374998 0.0009999933   0.9355387  0.9374998  0.9394610\n24 24 -1.6625001 0.0009999933  -1.6644612 -1.6625001 -1.6605389\n25 25  0.8374996 0.0009999933   0.8355385  0.8374996  0.8394608\n\n\n\nModel summary\n\nsummary(model_missing2)\n\n\nCall:\n   c(\"inla.core(formula = formula, family = family, contrasts = contrasts, \n   \", \" data = data, quantiles = quantiles, E = E, offset = offset, \", \" \n   scale = scale, weights = weights, Ntrials = Ntrials, strata = strata, \n   \", \" lp.scale = lp.scale, link.covariates = link.covariates, verbose = \n   verbose, \", \" lincomb = lincomb, selection = selection, control.compute \n   = control.compute, \", \" control.predictor = control.predictor, \n   control.family = control.family, \", \" control.inla = control.inla, \n   control.fixed = control.fixed, \", \" control.mode = control.mode, \n   control.expert = control.expert, \", \" control.hazard = control.hazard, \n   control.lincomb = control.lincomb, \", \" control.update = \n   control.update, control.lp.scale = control.lp.scale, \", \" \n   control.pardiso = control.pardiso, only.hyperparam = only.hyperparam, \n   \", \" inla.call = inla.call, inla.arg = inla.arg, num.threads = \n   num.threads, \", \" blas.num.threads = blas.num.threads, keep = keep, \n   working.directory = working.directory, \", \" silent = silent, inla.mode \n   = inla.mode, safe = FALSE, debug = debug, \", \" .parent.frame = \n   .parent.frame)\") \nTime used:\n    Pre = 3.04, Running = 0.275, Post = 0.0204, Total = 3.34 \nFixed effects:\n              mean     sd 0.025quant 0.5quant 0.975quant mode kld\nbeta.0     -32.246 10.999    -53.825  -32.333    -10.209   NA   0\nbeta.age2   49.780 16.772     16.172   49.906     82.716   NA   0\nbeta.age3   83.479 21.180     40.509   83.873    124.367   NA   0\nalpha.0      1.983  1.501     -0.979    1.978      4.978   NA   0\nalpha.age2  -3.126  2.361     -7.829   -3.120      1.544   NA   0\nalpha.age3  -4.525  2.487     -9.547   -4.494      0.320   NA   0\n\nRandom effects:\n  Name    Model\n    id.x IID model\n   beta.bmi Copy\n\nModel hyperparameters:\n                                            mean    sd 0.025quant 0.5quant\nPrecision for the Gaussian observations    0.001 0.001      0.001    0.001\nPrecision for the Gaussian observations[3] 0.063 0.016      0.036    0.062\nBeta for beta.bmi                          4.935 0.657      3.541    4.953\n                                           0.975quant mode\nPrecision for the Gaussian observations         0.003   NA\nPrecision for the Gaussian observations[3]      0.098   NA\nBeta for beta.bmi                               6.181   NA\n\nMarginal log-Likelihood:  -366.84 \n is computed \nPosterior summaries for the linear predictor and the fitted values are computed\n(Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\n\n\n\n\nReferences\nGómez-Rubio, V., & Rue, H. (2018). Markov chain Monte Carlo with the integrated nested Laplace approximation. Statistics and Computing, 28, 1033–1051. doi: 10.1007/s11222-017-9778-y"
  }
]